// MP4 å¯¼å‡º Worker - åè°ƒè§†é¢‘åˆæˆå’Œ MP4 å¯¼å‡º
// ä½¿ç”¨ video-composite-worker è¿›è¡Œåˆæˆï¼Œç„¶åç”¨ Mediabunny å¯¼å‡º MP4
import type { EncodedChunk, ExportOptions, BackgroundConfig, GradientConfig, ImageBackgroundConfig } from '../../types/background'
import { Mp4Strategy } from './strategies/mp4'
import { WebmStrategy } from './strategies/webm'
import { GifStrategy, type GifFrameData } from './strategies/gif'

import { Output, Mp4OutputFormat, BufferTarget, CanvasSource } from 'mediabunny'



interface ExportData {
  chunks: EncodedChunk[]
  options: ExportOptions
}

interface ProgressData {
  stage: 'preparing' | 'compositing' | 'encoding' | 'muxing' | 'finalizing'
  progress: number
  currentFrame: number
  totalFrames: number
  estimatedTimeRemaining?: number
  fileSize?: number
}

// Worker çŠ¶æ€
let isExporting = false
let shouldCancel = false
let compositeWorker: Worker | null = null
let offscreenCanvas: OffscreenCanvas | null = null
let canvasCtx: OffscreenCanvasRenderingContext2D | null = null
// å½“å‰å¯¼å‡ºçš„èƒŒæ™¯è‰²ï¼ˆç”¨äºå¯¹é½å¡«å……åŒºåŸŸï¼‰ï¼Œé»˜è®¤é»‘è‰²ä»¥å…¼å®¹æ’­æ”¾å™¨
let exportBgColor: string = '#000000'
// å½“å‰èƒŒæ™¯é…ç½®ï¼ˆç”¨äºæ¸å˜èƒŒæ™¯å¤„ç†ï¼‰
let currentBackgroundConfig: BackgroundConfig | null = null
// å½“å‰å¯¼å‡ºæ ¼å¼ï¼Œç”¨äºæ§åˆ¶è¿›åº¦æ›´æ–°é€»è¾‘
let currentExportFormat: string = ''

// ---- OPFS data processing utilities ----
function onceFromWorker<T = any>(worker: Worker, type: string, timeoutMs = 30000): Promise<T> {
  return new Promise((resolve, reject) => {
    let settled = false
    const handler = (e: MessageEvent) => {
      if (e.data?.type === type) {
        if (settled) return
        settled = true
        clearTimeout(timer)
        worker.removeEventListener('message', handler as any)
        resolve(e.data as T)
      }
    }
    const timer = setTimeout(() => {
      if (settled) return
      settled = true
      worker.removeEventListener('message', handler as any)
      reject(new Error(`Timeout waiting for worker message type '${type}' after ${timeoutMs}ms`))
    }, timeoutMs)
    worker.addEventListener('message', handler as any)
  })
}

// OPFS é©±åŠ¨å™¨çŠ¶æ€
let opfsReader: Worker | null = null
let opfsSummary: any = null
let opfsWindowSize = 90

let totalOpfsFrames = 0
let consumedGlobalFrames = 0
let currentWindowFrames = 0
let lastEmittedGlobalEnd = 0
let warnedCanvasSizeMismatch = false

let isOpfsMode = false

// è£å‰ªå‚æ•°
let trimStartFrame = 0
let trimEndFrame = Number.MAX_SAFE_INTEGER
let isTrimEnabled = false

async function initializeOpfsReader(dirId: string, windowSize?: number, trimOptions?: { startFrame: number, endFrame: number }): Promise<void> {
  try {

    opfsReader = new Worker(new URL('../opfs-reader-worker.ts', import.meta.url), { type: 'module' })
    opfsWindowSize = Math.max(30, Math.min(windowSize ?? 90, 150)) // é™åˆ¶çª—å£å¤§å°

    // æ‰“å¼€ OPFS ç›®å½•å¹¶è·å–æ‘˜è¦
    opfsReader.postMessage({ type: 'open', dirId })
    const ready: any = await onceFromWorker(opfsReader, 'ready')

    opfsSummary = ready?.summary || { totalChunks: 0 }
    totalOpfsFrames = Number(opfsSummary.totalChunks) || 0

    // âœ‚ï¸ åº”ç”¨è£å‰ªèŒƒå›´
    if (trimOptions) {
      isTrimEnabled = true
      trimStartFrame = Math.max(0, trimOptions.startFrame)
      trimEndFrame = Math.min(totalOpfsFrames - 1, trimOptions.endFrame)
      totalOpfsFrames = Math.max(0, trimEndFrame - trimStartFrame + 1)
    }

    consumedGlobalFrames = 0
    lastEmittedGlobalEnd = 0
    isOpfsMode = true


  } catch (error) {
    console.error('âŒ [MP4-Export-Worker] Failed to initialize OPFS reader:', error)
    throw error
  }
}

async function loadOpfsWindow(start: number, count: number): Promise<{ chunks: any[]; actualStart: number; actualCount: number }> {
  if (!opfsReader) {
    throw new Error('OPFS reader not initialized')
  }

  // âœ‚ï¸ åº”ç”¨è£å‰ªåç§»ï¼šå°†é€»è¾‘å¸§ç´¢å¼•è½¬æ¢ä¸ºç‰©ç†å¸§ç´¢å¼•
  let physicalStart = start
  let physicalCount = count

  if (isTrimEnabled) {
    physicalStart = trimStartFrame + start
    // ç¡®ä¿ä¸è¶…å‡ºè£å‰ªç»“æŸä½ç½®
    const maxCount = Math.max(0, trimEndFrame - physicalStart + 1)
    physicalCount = Math.min(count, maxCount)

  }


  opfsReader.postMessage({ type: 'getRange', start: physicalStart, count: physicalCount })
  const range: any = await onceFromWorker(opfsReader, 'range')

  const chunks = range?.chunks || []
  // è¿”å›é€»è¾‘å¸§ç´¢å¼•ï¼ˆç›¸å¯¹äºè£å‰ªåŒºé—´çš„åç§»ï¼‰
  const actualStart = isTrimEnabled ? Number(range?.start ?? physicalStart) - trimStartFrame : Number(range?.start ?? start)
  const actualCount = Number(range?.count ?? chunks.length ?? 0)


  return { chunks, actualStart, actualCount }
}

function cleanupOpfsReader(): void {
  if (opfsReader) {
    try {
      opfsReader.postMessage({ type: 'close' })
      opfsReader.terminate()
    } catch (e) {
      console.warn('âš ï¸ [MP4-Export-Worker] Error cleaning up OPFS reader:', e)
    }
    opfsReader = null
  }

  opfsSummary = null
  totalOpfsFrames = 0

  consumedGlobalFrames = 0
  lastEmittedGlobalEnd = 0
  isOpfsMode = false

  // âœ‚ï¸ é‡ç½®è£å‰ªå‚æ•°
  isTrimEnabled = false
  trimStartFrame = 0
  trimEndFrame = Number.MAX_SAFE_INTEGER
}
// ---- end OPFS data processing utilities ----

// è°ƒæ•´ Zoom åŒºé—´ä»¥é€‚é…è£å‰ªï¼ˆtrimï¼‰ï¼šå°†åŒºé—´æ•´ä½“å·¦ç§» trim.startMs å¹¶è£å‰ªåˆ°å¯¼å‡ºæ—¶é•¿
function adjustZoomForTrim(bg: any, trim?: { enabled?: boolean; startMs: number; endMs: number }) {
  try {
    if (!bg || !bg.videoZoom || !Array.isArray(bg.videoZoom.intervals)) return bg
    if (!trim?.enabled) return bg
    const start = Math.max(0, trim.startMs || 0)
    const end = Math.max(start, trim.endMs || start)
    const dur = Math.max(0, end - start)
    const intervals = bg.videoZoom.intervals
      .map((it: any) => ({ startMs: (it.startMs || 0) - start, endMs: (it.endMs || 0) - start }))
      .map((it: any) => ({
        startMs: Math.max(0, Math.min(it.startMs, dur)),
        endMs: Math.max(0, Math.min(it.endMs, dur))
      }))
      .filter((it: any) => it.endMs > it.startMs)
    return { ...bg, videoZoom: { ...bg.videoZoom, intervals, enabled: intervals.length > 0 } }
  } catch {
    return bg
  }
}


// åˆæˆçŠ¶æ€
let totalFrames = 0
let processedFrames = 0
let videoInfo: { width: number, height: number, frameRate: number } | null = null

// åˆ›å»ºæ¸å˜å¯¹è±¡
function createGradient(gradientConfig: GradientConfig, width: number, height: number): CanvasGradient | null {
  if (!canvasCtx) return null

  try {
    let gradient: CanvasGradient

    switch (gradientConfig.type) {
      case 'linear':
        const angle = gradientConfig.angle || 0
        const radians = (angle * Math.PI) / 180

        // è®¡ç®—æ¸å˜çš„èµ·ç‚¹å’Œç»ˆç‚¹
        const centerX = width / 2
        const centerY = height / 2
        const diagonal = Math.sqrt(width * width + height * height) / 2

        const x1 = centerX - Math.cos(radians) * diagonal
        const y1 = centerY - Math.sin(radians) * diagonal
        const x2 = centerX + Math.cos(radians) * diagonal
        const y2 = centerY + Math.sin(radians) * diagonal

        gradient = canvasCtx.createLinearGradient(x1, y1, x2, y2)
        break

      case 'radial':
        const centerX_r = (gradientConfig.centerX || 0.5) * width
        const centerY_r = (gradientConfig.centerY || 0.5) * height
        const radius = (gradientConfig.radius || 0.5) * Math.min(width, height)

        gradient = canvasCtx.createRadialGradient(centerX_r, centerY_r, 0, centerX_r, centerY_r, radius)
        break

      case 'conic':
        const centerX_c = (gradientConfig.centerX || 0.5) * width
        const centerY_c = (gradientConfig.centerY || 0.5) * height
        const angle_c = (gradientConfig.angle || 0) * Math.PI / 180

        gradient = canvasCtx.createConicGradient(angle_c, centerX_c, centerY_c)
        break

      default:
        console.warn('ğŸ¨ [MP4-Export-Worker] Unsupported gradient type:', (gradientConfig as any).type)
        return null
    }

    // æ·»åŠ é¢œè‰²åœæ­¢ç‚¹
    gradientConfig.stops.forEach(stop => {
      gradient.addColorStop(stop.position, stop.color)
    })

    return gradient
  } catch (error) {
    console.error('ğŸ¨ [MP4-Export-Worker] Error creating gradient:', error)
    return null
  }
}

// æ¸²æŸ“å›¾ç‰‡èƒŒæ™¯
function renderImageBackground(config: ImageBackgroundConfig, canvasWidth: number, canvasHeight: number) {
  if (!canvasCtx || !config.imageBitmap) return

  const { imageBitmap, fit, position, opacity, blur, scale, offsetX, offsetY } = config

  // ä¿å­˜çŠ¶æ€
  canvasCtx.save()

  // åº”ç”¨é€æ˜åº¦
  if (opacity !== undefined && opacity < 1) {
    canvasCtx.globalAlpha = opacity
  }

  // åº”ç”¨æ¨¡ç³Š
  if (blur && blur > 0) {
    canvasCtx.filter = `blur(${blur}px)`
  }

  // è®¡ç®—ç»˜åˆ¶å‚æ•°
  const drawParams = calculateImageDrawParams(
    imageBitmap.width,
    imageBitmap.height,
    canvasWidth,
    canvasHeight,
    fit,
    position,
    scale,
    offsetX,
    offsetY
  )

  // ç»˜åˆ¶å›¾ç‰‡
  canvasCtx.drawImage(
    imageBitmap,
    drawParams.x,
    drawParams.y,
    drawParams.width,
    drawParams.height
  )

  // æ¢å¤çŠ¶æ€
  canvasCtx.restore()
}

// è®¡ç®—å›¾ç‰‡ç»˜åˆ¶å‚æ•°
function calculateImageDrawParams(
  imageWidth: number,
  imageHeight: number,
  canvasWidth: number,
  canvasHeight: number,
  fit: string,
  position: string,
  scale: number = 1,
  offsetX: number = 0,
  offsetY: number = 0
): { x: number; y: number; width: number; height: number } {
  const imageAspect = imageWidth / imageHeight
  const canvasAspect = canvasWidth / canvasHeight

  let drawWidth: number, drawHeight: number

  // æ ¹æ®é€‚åº”æ¨¡å¼è®¡ç®—å°ºå¯¸
  switch (fit) {
    case 'cover':
      if (imageAspect > canvasAspect) {
        drawHeight = canvasHeight
        drawWidth = drawHeight * imageAspect
      } else {
        drawWidth = canvasWidth
        drawHeight = drawWidth / imageAspect
      }
      break
    case 'contain':
      if (imageAspect > canvasAspect) {
        drawWidth = canvasWidth
        drawHeight = drawWidth / imageAspect
      } else {
        drawHeight = canvasHeight
        drawWidth = drawHeight * imageAspect
      }
      break
    case 'fill':
      drawWidth = canvasWidth
      drawHeight = canvasHeight
      break
    case 'stretch':
    default:
      drawWidth = canvasWidth
      drawHeight = canvasHeight
      break
  }

  // åº”ç”¨ç¼©æ”¾
  drawWidth *= scale
  drawHeight *= scale

  // è®¡ç®—ä½ç½®
  let x: number, y: number

  // åŸºç¡€å±…ä¸­ä½ç½®
  x = (canvasWidth - drawWidth) / 2
  y = (canvasHeight - drawHeight) / 2

  // æ ¹æ®ä½ç½®è°ƒæ•´
  switch (position) {
    case 'top':
      y = 0
      break
    case 'bottom':
      y = canvasHeight - drawHeight
      break
    case 'left':
      x = 0
      break
    case 'right':
      x = canvasWidth - drawWidth
      break
    case 'top-left':
      x = 0
      y = 0
      break
    case 'top-right':
      x = canvasWidth - drawWidth
      y = 0
      break
    case 'bottom-left':
      x = 0
      y = canvasHeight - drawHeight
      break
    case 'bottom-right':
      x = canvasWidth - drawWidth
      y = canvasHeight - drawHeight
      break
    case 'center':
    default:
      // å·²ç»æ˜¯å±…ä¸­ä½ç½®
      break
  }

  // åº”ç”¨åç§»
  x += offsetX * canvasWidth
  y += offsetY * canvasHeight

  return { x, y, width: drawWidth, height: drawHeight }
}

// æ¸²æŸ“èƒŒæ™¯ï¼ˆæ”¯æŒæ¸å˜å’Œå›¾ç‰‡ï¼‰
function renderBackground(config: BackgroundConfig, width: number, height: number) {
  if (!canvasCtx) return

  if (config.type === 'gradient' && config.gradient) {
    // ä½¿ç”¨æ¸å˜èƒŒæ™¯
    const gradientStyle = createGradient(config.gradient, width, height)
    if (gradientStyle) {
      canvasCtx.fillStyle = gradientStyle
    } else {
      // å›é€€åˆ°çº¯è‰²
      canvasCtx.fillStyle = config.color
    }
    canvasCtx.fillRect(0, 0, width, height)
  } else if (config.type === 'image' && config.image) {
    // ç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡èƒŒæ™¯
    renderImageBackground(config.image, width, height)
  } else if (config.type === 'wallpaper' && config.wallpaper) {
    // å£çº¸èƒŒæ™¯
    renderImageBackground(config.wallpaper, width, height)
  } else {
    // çº¯è‰²èƒŒæ™¯
    canvasCtx.fillStyle = config.color
    canvasCtx.fillRect(0, 0, width, height)
  }
}

// æ¶ˆæ¯å¤„ç†
self.onmessage = async (event) => {
  const { type, data } = event.data

  try {
    switch (type) {
      case 'export':
        await handleExport(data as ExportData)
        break

      case 'cancel':
        handleCancel()
        break

      default:
        console.warn('âš ï¸ [MP4-Export-Worker] Unknown message type:', type)
    }
  } catch (error) {
    console.error('âŒ [MP4-Export-Worker] Error processing message:', error)
    self.postMessage({
      type: 'error',
      data: { error: (error as Error).message }
    })
  }

}

/**
 * å¤„ç†å¯¼å‡ºè¯·æ±‚
 */
async function handleExport(exportData: ExportData) {
  if (isExporting) {
    throw new Error('Export already in progress')
  }

  isExporting = true
  shouldCancel = false

  try {
    const { chunks, options } = exportData

    // è®°å½•å½“å‰å¯¼å‡ºæ ¼å¼
    currentExportFormat = options?.format || ''

    // âœ‚ï¸ å°† Zoom åŒºé—´ä¸è£å‰ªæ—¶é—´å¯¹é½ï¼šå¹³ç§»å¹¶è£å‰ªåˆ°å¯¼å‡ºåŒºé—´
    try {
      (options as any).backgroundConfig = adjustZoomForTrim((options as any).backgroundConfig, (options as any).trim)
    } catch {}


    // åˆ†æ”¯ï¼šWebM å…¼å®¹è·¯å¾„ï¼ˆä¿æŒåŸ webm-export-worker è¡Œä¸ºï¼šä¸ä½¿ç”¨ OPFS çª—å£/æµå¼ï¼‰
    if (options?.format === 'webm') {
      // æ›´æ–°è¿›åº¦ï¼šå‡†å¤‡é˜¶æ®µ
      updateProgress({ stage: 'preparing', progress: 5, currentFrame: 0, totalFrames: chunks.length })
      if (shouldCancel) return

      // 1) åˆ›å»ºå¹¶åˆå§‹åŒ– composite worker
      await createCompositeWorker()
      if (shouldCancel) return

      // 2) å¤„ç†è§†é¢‘åˆæˆï¼ˆOPFS/å†…å­˜ï¼‰
      if ((options as any)?.source === 'opfs' && (options as any)?.opfsDirId) {
        // âœ‚ï¸ å‡†å¤‡è£å‰ªå‚æ•°
        const trimOptions = options.trim?.enabled ? {
          startFrame: options.trim.startFrame,
          endFrame: options.trim.endFrame
        } : undefined
        await initializeOpfsReader((options as any).opfsDirId, (options as any).windowSize, trimOptions)
        const { chunks: firstChunks, actualStart } = await loadOpfsWindow(0, opfsWindowSize)
        await processVideoCompositionOpfs(firstChunks, options, actualStart)
      } else {
        await processVideoComposition(chunks, options)
      }
      if (shouldCancel) return

      // 3) å¯¼å‡º WebMï¼ˆæ”¯æŒ OPFS æµå¼å†™å…¥ï¼‰
      const webmResult: any = await exportToWEBMCompat(options)
      if (shouldCancel) return

      if (webmResult && (webmResult as any).savedToOpfs) {
        self.postMessage({ type: 'complete', data: { savedToOpfs: (webmResult as any).savedToOpfs } })
      } else {
        self.postMessage({ type: 'complete', data: { blob: webmResult as Blob } })
      }
      return
    }

    // åˆ†æ”¯ï¼šGIF å¯¼å‡ºè·¯å¾„
    if (options?.format === 'gif') {

      // æ›´æ–°è¿›åº¦ï¼šå‡†å¤‡é˜¶æ®µ
      updateProgress({ stage: 'preparing', progress: 5, currentFrame: 0, totalFrames: chunks.length })
      if (shouldCancel) return

      // 1) åˆ›å»ºå¹¶åˆå§‹åŒ– composite worker
      await createCompositeWorker()
      if (shouldCancel) return

      // 2) å¤„ç†è§†é¢‘åˆæˆ
      if ((options as any)?.source === 'opfs' && (options as any)?.opfsDirId) {
        const trimOptions = options.trim?.enabled ? {
          startFrame: options.trim.startFrame,
          endFrame: options.trim.endFrame
        } : undefined
        await initializeOpfsReader((options as any).opfsDirId, (options as any).windowSize, trimOptions)
        const { chunks: firstChunks, actualStart } = await loadOpfsWindow(0, opfsWindowSize)
        await processVideoCompositionOpfs(firstChunks, options, actualStart)
      } else {
        await processVideoComposition(chunks, options)
      }
      if (shouldCancel) return

      // 3) å¯¼å‡º GIF
      const gifResult = await exportToGIF(options)
      if (shouldCancel) return

      self.postMessage({ type: 'complete', data: { blob: gifResult as Blob } })
      return
    }

    // é»˜è®¤ï¼šMP4 è·¯å¾„ï¼ˆä¿ç•™ç°æœ‰ MP4 è¡Œä¸ºï¼‰

    // å½“æ¥æºä¸º OPFS æ—¶ï¼Œåˆå§‹åŒ– OPFS è¯»å–å™¨ï¼ˆç”¨äºå®é™…å¯¼å‡ºï¼‰
    if ((options as any)?.source === 'opfs' && (options as any)?.opfsDirId) {
      // âœ‚ï¸ å‡†å¤‡è£å‰ªå‚æ•°
      const trimOptions = options.trim?.enabled ? {
        startFrame: options.trim.startFrame,
        endFrame: options.trim.endFrame
      } : undefined
      await initializeOpfsReader((options as any).opfsDirId, (options as any).windowSize, trimOptions)
    }

    // æ›´æ–°è¿›åº¦ï¼šå‡†å¤‡é˜¶æ®µ
    updateProgress({
      stage: 'preparing',
      progress: 5,
      currentFrame: 0,
      totalFrames: (((options as any)?.source === 'opfs' && totalOpfsFrames > 0) ? totalOpfsFrames : chunks.length)
    })

    if (shouldCancel) return

    // 1. åˆ›å»ºå¹¶åˆå§‹åŒ– video-composite-worker
    await createCompositeWorker()

    if (shouldCancel) return

    // 2. å¤„ç†è§†é¢‘åˆæˆ
    if (((options as any)?.source === 'opfs') && totalOpfsFrames > 0) {
      // OPFS æ¨¡å¼ï¼šå…ˆå¤„ç†é¦–çª—å£ï¼Œè§¦å‘ composite readyï¼ˆåˆ›å»º OffscreenCanvas/è®¾ç½® videoInfoï¼‰
      const { chunks: firstChunks, actualStart } = await loadOpfsWindow(0, opfsWindowSize)
      await processVideoCompositionOpfs(firstChunks, options, actualStart)
      // è®°å½•ä¸‹ä¸€çª—å£èµ·ç‚¹ï¼Œä¾›æ¸²æŸ“å¾ªç¯è·³è¿‡é¦–çª—ï¼ˆé¿å…é‡å¤ï¼‰
      // ä¸è·³è¿‡é¦–çª—ï¼šç”±æ¸²æŸ“å¾ªç¯æŒ‰å»é‡é€»è¾‘å†³å®šæ˜¯å¦è¾“å‡ºï¼Œé¿å…ä¸¢å¸§
    } else {
      // é OPFS æ¨¡å¼ï¼ŒæŒ‰å†…å­˜ chunks å¤„ç†ä¸€æ¬¡
      await processVideoComposition(chunks, options)
    }

    if (shouldCancel) return

    // 3. å¯¼å‡º MP4ï¼ˆæ”¯æŒå†…å­˜æˆ– OPFS æµå¼å†™å…¥ï¼‰
    const result: any = await exportToMP4(options)

    if (shouldCancel) return

    // å®Œæˆå¯¼å‡º
    if (result && (result as any).savedToOpfs) {
      self.postMessage({ type: 'complete', data: { savedToOpfs: (result as any).savedToOpfs } })
    } else {
      self.postMessage({ type: 'complete', data: { blob: result as Blob } })
    }

  } catch (error) {
    console.error('âŒ [Export-Worker] Export failed:', error)
    self.postMessage({
      type: 'error',
      data: { error: (error as Error).message }
    })
  } finally {
    cleanup()
    isExporting = false
  }
}

/**
 * åˆ›å»º video-composite-worker
 */
async function createCompositeWorker(): Promise<void> {
  return new Promise((resolve, reject) => {
    try {
      // åˆ›å»º composite worker
      compositeWorker = new Worker(
        new URL('../composite-worker/index.ts', import.meta.url),
        { type: 'module' }
      )

      // è®¾ç½®æ¶ˆæ¯å¤„ç†
      compositeWorker.onmessage = (event) => {
        const { type, data } = event.data

        switch (type) {
          case 'initialized':
            resolve()
            break

          case 'ready':
            totalFrames = data.totalFrames
            if (!videoInfo) {
              videoInfo = {
                width: data.outputSize.width,
                height: data.outputSize.height,
                frameRate: 30 // é»˜è®¤å¸§ç‡
              }
            }

            // ä»…åœ¨é¦–æ¬¡ ready æ—¶åˆ›å»º OffscreenCanvasï¼›åç»­çª—å£ä¸é‡å¤åˆ›å»ºï¼Œä»¥å…ä¸ CanvasSource ç»‘å®šçš„ç”»å¸ƒå¤±è”å¯¼è‡´é»‘å±
            if (!offscreenCanvas) {
              createOffscreenCanvas(data.outputSize.width, data.outputSize.height)
            } else {
              // å¯é€‰ï¼šå¦‚æœå°ºå¯¸ä¸åŒï¼Œè®°å½•æ—¥å¿—ä½†ä¿æŒç°æœ‰ç”»å¸ƒï¼Œé¿å…ç ´å CanvasSource å¼•ç”¨
              if (offscreenCanvas.width !== data.outputSize.width || offscreenCanvas.height !== data.outputSize.height) {
                if (!warnedCanvasSizeMismatch) {
                  console.warn('âš ï¸ [MP4-Export-Worker] Ready reports different size after canvas created; keep existing canvas to avoid black frames:', {
                    existing: { w: offscreenCanvas.width, h: offscreenCanvas.height },
                    reported: data.outputSize
                  })
                  warnedCanvasSizeMismatch = true
                }
              }
            }
            break

          case 'frame':
            // æ¥æ”¶åˆæˆåçš„å¸§
            handleCompositeFrame(data.bitmap, data.frameIndex)
            break

          case 'complete':
            break

          case 'error':
            console.error('âŒ [MP4-Export-Worker] Composite worker error:', data)
            reject(new Error(data.error || 'Composite worker error'))
            break
        }
      }

      compositeWorker.onerror = (error) => {
        console.error('âŒ [MP4-Export-Worker] Composite worker error:', error)
        reject(error)
      }

      // åˆå§‹åŒ– composite worker
      compositeWorker.postMessage({ type: 'init' })

    } catch (error) {
      reject(error)
    }
  })
}

/**
 * åˆ›å»º OffscreenCanvasï¼ˆH.264 å…¼å®¹å°ºå¯¸ï¼‰
 */
function createOffscreenCanvas(width: number, height: number) {
  // ğŸ”§ ç¡®ä¿ Canvas å°ºå¯¸ç¬¦åˆ H.264 è¦æ±‚
  const { width: h264Width, height: h264Height, modified } = validateAndFixH264Dimensions(width, height)

  if (modified) {
  }

  offscreenCanvas = new OffscreenCanvas(h264Width, h264Height)
  canvasCtx = offscreenCanvas.getContext('2d')

  if (!canvasCtx) {
    throw new Error('Failed to get 2D context from OffscreenCanvas')
  }

  // å¦‚æœå°ºå¯¸è¢«è°ƒæ•´ï¼Œéœ€è¦æ›´æ–° videoInfo
  if (modified && videoInfo) {
    videoInfo.width = h264Width
    videoInfo.height = h264Height
  }

}

/**
 * å¤„ç†è§†é¢‘åˆæˆ
 */
async function processVideoComposition(chunks: EncodedChunk[], options: ExportOptions): Promise<void> {
  // è®°å½•èƒŒæ™¯é…ç½®ï¼Œä¾› MP4 ç”»å¸ƒåœ¨å¯¹é½å¡«å……æ—¶ä½¿ç”¨
  try {
    currentBackgroundConfig = options.backgroundConfig || null
    exportBgColor = options.backgroundConfig?.color || exportBgColor
  } catch {}

  return new Promise((resolve, reject) => {
    if (!compositeWorker) {
      reject(new Error('Composite worker not available'))
      return
    }

    // GIF å¯¼å‡ºæ—¶ä¸åœ¨è¿™é‡Œæ›´æ–°è¿›åº¦ï¼Œç”±å¸§æ”¶é›†æ§åˆ¶
    // å…¶ä»–æ ¼å¼ï¼ˆMP4/WebMï¼‰ä»ç„¶éœ€è¦æ›´æ–°
    if (options.format !== 'gif') {
      updateProgress({
        stage: 'compositing',
        progress: 10,
        currentFrame: 0,
        totalFrames: chunks.length
      })
    }

    // å‡†å¤‡å¯ä¼ è¾“çš„æ•°æ®å—ï¼ˆå…¼å®¹ Uint8Array / ArrayBufferï¼‰
    const transferableChunks = chunks.map((chunk: any) => {
      let buf: ArrayBuffer
      if (chunk.data instanceof ArrayBuffer) buf = chunk.data
      else if (chunk.data?.buffer) buf = chunk.data.buffer.slice(chunk.data.byteOffset, chunk.data.byteOffset + chunk.data.byteLength)
      else buf = chunk.data
      return {
        data: buf,
        timestamp: chunk.timestamp,
        type: chunk.type,
        size: chunk.size,
        codedWidth: chunk.codedWidth,
        codedHeight: chunk.codedHeight,
        codec: chunk.codec
      }
    })

    // æ”¶é›†æ‰€æœ‰ ArrayBuffer ç”¨äºè½¬ç§»
    const transferList = transferableChunks.map(chunk => chunk.data)

    // å‘é€å¤„ç†è¯·æ±‚åˆ° composite worker
    compositeWorker.postMessage({
      type: 'process',
      data: {
        chunks: transferableChunks,
        backgroundConfig: options.backgroundConfig || {
          type: 'solid-color',
          color: '#000000',
          padding: 0,
          outputRatio: '16:9',
          videoPosition: 'center'
        },
        // propagate export framerate for consistent zoom timing
        frameRate: (options as any)?.framerate || 30
      }
    }, { transfer: transferList })

    // ç­‰å¾…å¤„ç†å®Œæˆ
    const originalOnMessage = compositeWorker.onmessage
    compositeWorker.onmessage = (event) => {
      const { type, data } = event.data

      if (type === 'ready') {
        // æ¢å¤åŸå§‹æ¶ˆæ¯å¤„ç†
        compositeWorker!.onmessage = originalOnMessage
        if (originalOnMessage && compositeWorker) {
          originalOnMessage.call(compositeWorker, event)
        }
        resolve()
      } else if (type === 'error') {
        reject(new Error(data.error || 'Composition failed'))
      } else {
        // è½¬å‘å…¶ä»–æ¶ˆæ¯
        if (originalOnMessage && compositeWorker) {
          originalOnMessage.call(compositeWorker, event)
        }
      }
    }
  })
}

// ä¸“ç”¨äº OPFS
async function processVideoCompositionOpfs(wireChunks: any[], options: ExportOptions, startGlobalFrame: number): Promise<void> {
  try {
    currentBackgroundConfig = options.backgroundConfig || null
    exportBgColor = options.backgroundConfig?.color || exportBgColor
  } catch {}

  return new Promise((resolve, reject) => {
    if (!compositeWorker) {
      reject(new Error('Composite worker not available'))
      return
    }

    // GIF å¯¼å‡ºæ—¶ä¸åœ¨è¿™é‡Œæ›´æ–°è¿›åº¦ï¼Œç”±å¸§æ”¶é›†æ§åˆ¶
    if (options.format !== 'gif') {
      updateProgress({
        stage: 'compositing',
        progress: 10,
        currentFrame: isOpfsMode ? lastEmittedGlobalEnd : consumedGlobalFrames,
        totalFrames: (totalOpfsFrames > 0 ? totalOpfsFrames : wireChunks.length)
      })
    }

    const transferable = wireChunks.map((c: any) => ({
      data: c.data as ArrayBuffer,
      timestamp: c.timestamp,
      type: c.type,
      size: c.size,
      codedWidth: c.codedWidth,
      codedHeight: c.codedHeight,
      codec: c.codec
    }))
    const transferList = transferable.map(c => c.data)

    const originalOnMessage = compositeWorker.onmessage
    compositeWorker.onmessage = (event) => {
      const { type, data } = event.data
      if (type === 'ready') {
        // è®°å½•å½“å‰çª—å£å¸§æ•°ï¼ˆç”± composite worker åŸºäº chunks.length è¿”å›ï¼‰
        try {
          currentWindowFrames = Number(data?.totalFrames) || transferable.length
        } catch {}
        compositeWorker!.onmessage = originalOnMessage
        if (originalOnMessage && compositeWorker) {
          originalOnMessage.call(compositeWorker, event)
        }
        resolve()
      } else if (type === 'error') {
        compositeWorker!.onmessage = originalOnMessage
        reject(new Error(data.error || 'Composition failed'))
      } else {
        if (originalOnMessage && compositeWorker) {
          originalOnMessage.call(compositeWorker, event)
        }
      }
    }

    compositeWorker.postMessage({
      type: 'process',
      data: {
        chunks: transferable,
        backgroundConfig: options.backgroundConfig || {
          type: 'solid-color', color: '#000000', padding: 0, outputRatio: '16:9', videoPosition: 'center'
        },
        startGlobalFrame,
        // prefer provided framerate, fallback to OPFS meta fps, finally 30
        frameRate: (options as any)?.framerate || (opfsSummary?.meta?.fps) || 30
      }
    }, { transfer: transferList })
  })
}

/**
 * å¤„ç†åˆæˆå¸§
 */
function handleCompositeFrame(bitmap: ImageBitmap, frameIndex: number) {
  // ğŸ”§ ä¼˜åŒ–ï¼šç¡®ä¿ bitmap åœ¨æ‰€æœ‰è·¯å¾„éƒ½è¢«é‡Šæ”¾
  let bitmapClosed = false

  const closeBitmap = () => {
    if (!bitmapClosed && bitmap) {
      try {
        bitmap.close()
        bitmapClosed = true
      } catch (e) {
        console.warn('[MP4-Export-Worker] Failed to close bitmap:', e)
      }
    }
  }

  if (!canvasCtx || !offscreenCanvas) {
    console.error('âŒ [MP4-Export-Worker] Canvas not available')
    closeBitmap()
    return
  }

  try {
    const canvasWidth = offscreenCanvas.width
    const canvasHeight = offscreenCanvas.height

    // å…ˆç”¨èƒŒæ™¯å¡«å……æ•´ä¸ªç”»å¸ƒï¼Œé¿å… H.264 æ— é€æ˜åº¦å¯¼è‡´çš„é»‘è¾¹
    try {
      if (currentBackgroundConfig) {
        // ä½¿ç”¨å®Œæ•´çš„èƒŒæ™¯é…ç½®ï¼ˆæ”¯æŒæ¸å˜ï¼‰
        renderBackground(currentBackgroundConfig, canvasWidth, canvasHeight)
      } else {
        // å›é€€åˆ°çº¯è‰²
        canvasCtx.fillStyle = exportBgColor
        canvasCtx.fillRect(0, 0, canvasWidth, canvasHeight)
      }
    } catch (error) {
      console.warn('ğŸ¨ [MP4-Export-Worker] Background render failed, using fallback:', error)
      canvasCtx.fillStyle = exportBgColor
      canvasCtx.fillRect(0, 0, canvasWidth, canvasHeight)
    }

    // ğŸ”§ æ™ºèƒ½é€‚é…ï¼šå°½é‡é¿å…å›  H.264 å¯¹é½(ä¾‹å¦‚ 1080â†’1088)å¸¦æ¥çš„ç¼©æ”¾
    const bitmapWidth = bitmap.width
    const bitmapHeight = bitmap.height

    if (bitmapWidth !== canvasWidth || bitmapHeight !== canvasHeight) {
      const widthDiff = canvasWidth - bitmapWidth
      const heightDiff = canvasHeight - bitmapHeight
      const smallDiff = Math.abs(widthDiff) <= 16 && Math.abs(heightDiff) <= 16
      const singleDimDiff = (widthDiff === 0 && heightDiff !== 0) || (heightDiff === 0 && widthDiff !== 0)

      if (smallDiff && singleDimDiff) {
        // ä»…å› å¯¹é½äº§ç”Ÿçš„ä¸€ä¾§å·®å¼‚ï¼šä¸ç¼©æ”¾ï¼Œå±…ä¸­æ”¾ç½®ï¼Œå‰©ä½™åŒºåŸŸä»¥èƒŒæ™¯è‰²å¡«å……
        const offsetX = Math.max(0, widthDiff / 2)
        const offsetY = Math.max(0, heightDiff / 2)
        canvasCtx.drawImage(bitmap, offsetX, offsetY)
      } else {
        // è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼Œä¿æŒçºµæ¨ªæ¯”
        const scaleX = canvasWidth / bitmapWidth
        const scaleY = canvasHeight / bitmapHeight
        const scale = Math.min(scaleX, scaleY)

        const scaledWidth = bitmapWidth * scale
        const scaledHeight = bitmapHeight * scale
        const offsetX = (canvasWidth - scaledWidth) / 2
        const offsetY = (canvasHeight - scaledHeight) / 2

        if (!warnedCanvasSizeMismatch) {
          console.log(`ğŸ”§ [MP4-Export-Worker] Scaling frames: Bitmap ${bitmapWidth}Ã—${bitmapHeight} â†’ Canvas ${canvasWidth}Ã—${canvasHeight}, scale=${scale.toFixed(3)}`)
          warnedCanvasSizeMismatch = true
        }
        // ç»˜åˆ¶ç¼©æ”¾åçš„å›¾åƒ
        canvasCtx.drawImage(bitmap, offsetX, offsetY, scaledWidth, scaledHeight)
      }
    } else {
      // å°ºå¯¸ä¸€è‡´ï¼Œç›´æ¥ç»˜åˆ¶
      canvasCtx.drawImage(bitmap, 0, 0)
    }

    processedFrames++

    // GIF å¯¼å‡ºæ—¶ä¸åœ¨è¿™é‡Œæ›´æ–°è¿›åº¦ï¼Œç”±å¸§æ”¶é›†æ§åˆ¶
    // å…¶ä»–æ ¼å¼ï¼ˆMP4/WebMï¼‰ä»ç„¶éœ€è¦æ›´æ–°
    if (currentExportFormat !== 'gif') {
      const progress = 20 + (processedFrames / totalFrames) * 50 // 20%-70%
      updateProgress({
        stage: 'compositing',
        progress,
        currentFrame: processedFrames,
        totalFrames: isOpfsMode ? totalOpfsFrames : totalFrames
      })
    }

    const totalForLog = isOpfsMode ? totalOpfsFrames : totalFrames

  } catch (error) {
    console.error('âŒ [MP4-Export-Worker] Error handling composite frame:', error)
  } finally {
    // ğŸ”§ ä¼˜åŒ–ï¼šç¡®ä¿ bitmap åœ¨æ‰€æœ‰è·¯å¾„éƒ½è¢«é‡Šæ”¾ï¼Œé¿å…å†…å­˜æ³„æ¼
    closeBitmap()
  }
}


/**
 * éªŒè¯ MP4 Blob
 */
function validateMP4Blob(blob: Blob, addedFrames: number, totalFrames: number): { isValid: boolean; issues: string[] } {
  const issues: string[] = []

  // æ£€æŸ¥æ–‡ä»¶å¤§å°
  if (blob.size === 0) {
    issues.push('æ–‡ä»¶å¤§å°ä¸º 0')
  } else if (blob.size < 1000) {
    issues.push('æ–‡ä»¶å¤§å°è¿‡å°ï¼Œå¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„ MP4 æ–‡ä»¶')
  }

  // æ£€æŸ¥ MIME ç±»å‹
  if (blob.type !== 'video/mp4') {
    issues.push(`MIME ç±»å‹ä¸æ­£ç¡®: ${blob.type}ï¼ŒæœŸæœ›: video/mp4`)
  }

  // æ£€æŸ¥å¸§æ•°åŒ¹é…
  const frameSuccessRate = addedFrames / totalFrames
  if (frameSuccessRate < 0.5) {
    issues.push(`å¸§æ·»åŠ æˆåŠŸç‡è¿‡ä½: ${(frameSuccessRate * 100).toFixed(1)}%`)
  }

  // ä¼°ç®—åˆç†çš„æ–‡ä»¶å¤§å°èŒƒå›´
  const estimatedMinSize = addedFrames * 1000 // æ¯å¸§è‡³å°‘ 1KB
  const estimatedMaxSize = addedFrames * 100000 // æ¯å¸§æœ€å¤š 100KB

  if (blob.size < estimatedMinSize) {
    issues.push(`æ–‡ä»¶å¤§å°è¿‡å°: ${blob.size} bytesï¼ŒæœŸæœ›è‡³å°‘: ${estimatedMinSize} bytes`)
  } else if (blob.size > estimatedMaxSize) {
    issues.push(`æ–‡ä»¶å¤§å°è¿‡å¤§: ${blob.size} bytesï¼ŒæœŸæœ›æœ€å¤š: ${estimatedMaxSize} bytes`)
  }

  return {
    isValid: issues.length === 0,
    issues
  }
}

/**
 * æ£€æŸ¥ Mediabunny åº“çŠ¶æ€
 */
function checkMediabunnyStatus(): { available: boolean; reason: string } {
  try {
    // æ£€æŸ¥ Mediabunny ç±»æ˜¯å¦å¯ç”¨
    if (typeof Output === 'undefined') {
      return { available: false, reason: 'Output ç±»ä¸å¯ç”¨' }
    }
    if (typeof Mp4OutputFormat === 'undefined') {
      return { available: false, reason: 'Mp4OutputFormat ç±»ä¸å¯ç”¨' }
    }
    if (typeof BufferTarget === 'undefined') {
      return { available: false, reason: 'BufferTarget ç±»ä¸å¯ç”¨' }
    }
    if (typeof CanvasSource === 'undefined') {
      return { available: false, reason: 'CanvasSource ç±»ä¸å¯ç”¨' }
    }

    return { available: true, reason: 'æ‰€æœ‰ Mediabunny ç±»éƒ½å¯ç”¨' }
  } catch (error) {
    return { available: false, reason: `Mediabunny æ£€æŸ¥å¤±è´¥: ${(error as Error).message}` }
  }
}

/**
 * éªŒè¯å’Œä¿®å¤ H.264 å…¼å®¹çš„å°ºå¯¸
 */
function validateAndFixH264Dimensions(width: number, height: number): { width: number; height: number; modified: boolean } {
  const originalWidth = width
  const originalHeight = height

  // ç¡®ä¿å°ºå¯¸æ˜¯å¶æ•°ï¼ˆH.264 è¦æ±‚ï¼‰
  let fixedWidth = width % 2 === 0 ? width : width + 1
  let fixedHeight = height % 2 === 0 ? height : height + 1

  // ç¡®ä¿æœ€å°å°ºå¯¸ï¼ˆ16Ã—16ï¼‰
  fixedWidth = Math.max(fixedWidth, 16)
  fixedHeight = Math.max(fixedHeight, 16)

  // æ¨èï¼šè°ƒæ•´ä¸º 16 çš„å€æ•°ä»¥è·å¾—æœ€ä½³æ€§èƒ½
  const alignedWidth = Math.ceil(fixedWidth / 16) * 16
  const alignedHeight = Math.ceil(fixedHeight / 16) * 16

  const modified = (alignedWidth !== originalWidth) || (alignedHeight !== originalHeight)

  if (modified) {
  }

  return {
    width: alignedWidth,
    height: alignedHeight,
    modified
  }
}

/**
 * æ£€æŸ¥ H.264 ç¼–ç å™¨æ”¯æŒ
 */
async function checkH264Support(): Promise<{ supported: boolean; reason: string }> {
  try {
    // æ£€æŸ¥ WebCodecs API å¯ç”¨æ€§
    if (typeof VideoEncoder === 'undefined') {
      return { supported: false, reason: 'WebCodecs API ä¸å¯ç”¨' }
    }

    // è·å–å¹¶éªŒè¯è§†é¢‘å°ºå¯¸
    const originalWidth = videoInfo?.width || 1920
    const originalHeight = videoInfo?.height || 1080
    const { width, height, modified } = validateAndFixH264Dimensions(originalWidth, originalHeight)

    if (modified) {
    }

    // æµ‹è¯• H.264 ç¼–ç å™¨é…ç½®
    const testConfigs = [
      'avc1.42001e',  // Baseline Profile Level 3.0
      'avc1.42E01E',  // Baseline Profile Level 3.0 (alternative)
      'avc1.4D001E',  // Main Profile Level 3.0
      'avc1.640028'   // High Profile Level 4.0
    ]

    for (const codec of testConfigs) {
      try {
        const config = {
          codec,
          width,  // ä½¿ç”¨ä¿®æ­£åçš„å°ºå¯¸
          height, // ä½¿ç”¨ä¿®æ­£åçš„å°ºå¯¸
          bitrate: 2000000,
          framerate: 30
        }

        const support = await VideoEncoder.isConfigSupported(config)
        if (support.supported) {
          return { supported: true, reason: `æ”¯æŒ ${codec} (${width}Ã—${height})` }
        } else {
        }
      } catch (error) {
      }
    }

    return { supported: false, reason: `æ‰€æœ‰ H.264 é…ç½®éƒ½ä¸æ”¯æŒ (æµ‹è¯•å°ºå¯¸: ${width}Ã—${height})` }
  } catch (error) {
    return { supported: false, reason: `æ£€æµ‹å¤±è´¥: ${(error as Error).message}` }
  }
}

/**
 * å¯¼å‡º MP4
 */



async function exportToMP4(options: ExportOptions): Promise<any> {
  if (!offscreenCanvas || !videoInfo) {
    throw new Error('Canvas or video info not available')
  }


  try {
    // ğŸ”§ é¦–å…ˆæ£€æŸ¥ Mediabunny åº“çŠ¶æ€
    const mediabunnyStatus = checkMediabunnyStatus()

    if (!mediabunnyStatus.available) {
      throw new Error(`Mediabunny åº“ä¸å¯ç”¨: ${mediabunnyStatus.reason}`)
    }

    // ğŸ”§ ç„¶åæ£€æŸ¥ H.264 ç¼–ç å™¨æ”¯æŒ
    const h264Support = await checkH264Support()

    if (!h264Support.supported) {
      throw new Error(`H.264 ç¼–ç å™¨ä¸æ”¯æŒ: ${h264Support.reason}ã€‚è¯·å°è¯•å¯¼å‡ºä¸º WebM æ ¼å¼ã€‚`)
    }

    const strategy = new Mp4Strategy()

    // æ›´æ–°è¿›åº¦ï¼šç¼–ç é˜¶æ®µ
    updateProgress({
      stage: 'encoding',
      progress: 75,
      currentFrame: 0,
      totalFrames: 100
    })

    // åˆ›å»º Mediabunny è¾“å‡ºï¼ˆä½¿ç”¨ç­–ç•¥ï¼Œæ”¯æŒ OPFS æµå¼å†™å…¥ï¼‰

    const useOpfsStream = Boolean((options as any)?.saveToOpfs && (options as any)?.opfsDirId)
    const { output } = await strategy.createOutput(useOpfsStream, options)

    // åˆ›å»º CanvasSourceï¼ˆé€šè¿‡ç­–ç•¥ï¼‰

    const videoSource = strategy.createVideoSource(offscreenCanvas, { bitrate: options.bitrate || 8000000 })


    // æ·»åŠ è§†é¢‘è½¨é“
    output.addVideoTrack(videoSource)

    // å¯åŠ¨è¾“å‡ºï¼ˆäº¤ç”±ç­–ç•¥å¤„ç†ï¼‰
    await strategy.start(output)

    // æ›´æ–°è¿›åº¦ï¼šå°è£…é˜¶æ®µ
    updateProgress({
      stage: 'muxing',
      progress: 80,
      currentFrame: isOpfsMode ? lastEmittedGlobalEnd : 0,
      totalFrames: isOpfsMode ? totalOpfsFrames : totalFrames
    })

    // è®¡ç®—å¸§å‚æ•°ï¼ˆOPFS æ¨¡å¼ä¸‹ videoInfo å¯èƒ½å°šæœªé€šè¿‡ ready è¿”å›ï¼Œä¼˜å…ˆä½¿ç”¨ options æˆ–é»˜è®¤å€¼ï¼‰
    const frameRate = (options as any)?.framerate || videoInfo?.frameRate || 30
    const totalTargetFrames = isOpfsMode ? totalOpfsFrames : totalFrames
    const duration = totalTargetFrames / frameRate
    const frameDuration = 1 / frameRate


    // è¯·æ±‚ composite worker é€å¸§æ¸²æŸ“å¹¶æ·»åŠ åˆ° CanvasSource
    const addedFrames = isOpfsMode
      ? await renderFramesForExportOpfs(videoSource, frameDuration, options)
      : await renderFramesForExport(videoSource, frameDuration)

    // ğŸ”§ ä¿®å¤ï¼šæ›´å®½æ¾çš„é”™è¯¯æ£€æŸ¥ï¼Œä¸ WebM Worker ä¿æŒä¸€è‡´
    if (addedFrames === 0) {
      console.error('âŒ [MP4-Export-Worker] æœªæˆåŠŸå‘ H.264 ç¼–ç å™¨æ·»åŠ ä»»ä½•å¸§')
      throw new Error('MP4 å¯¼å‡ºå¤±è´¥ï¼šæœªèƒ½æ·»åŠ ä»»ä½•å¸§åˆ°ç¼–ç å™¨ã€‚å¯èƒ½åŸå› ï¼š1) åˆæˆ Worker é€šä¿¡å¤±è´¥ 2) H.264 ç¼–ç å™¨ä¸å¯ç”¨ 3) å¸§æ¸²æŸ“è¶…æ—¶')
    } else if (addedFrames < totalFrames * 0.8) {
      console.warn(`âš ï¸ [MP4-Export-Worker] åªæˆåŠŸæ·»åŠ äº† ${addedFrames}/${totalFrames} å¸§ (${((addedFrames/totalFrames)*100).toFixed(1)}%)ï¼Œä½†ç»§ç»­å¯¼å‡º`)
    } else {
    }

    // å®Œæˆè¾“å‡º
    updateProgress({
      stage: 'finalizing',
      progress: 95,
      currentFrame: (isOpfsMode ? totalOpfsFrames : totalFrames),
      totalFrames: (isOpfsMode ? totalOpfsFrames : totalFrames)
    })

    // å®Œæˆè¾“å‡ºï¼ˆäº¤ç”±ç­–ç•¥å¤„ç†ï¼‰ï¼Œå¹¶å…³é—­è§†é¢‘æº
    await strategy.finalize(output)
    try { if (videoSource) { strategy.closeVideoSource?.(videoSource) } } catch {}

    // è·å–ç»“æœ
    if (useOpfsStream) {
      const info = (await (strategy.getOpfsResultInfo?.(options as any) || Promise.resolve({ bytes: 0, fileName: (options as any).opfsFileName || 'export.mp4' }))) as { bytes: number; fileName: string }


      // æœ€ç»ˆè¿›åº¦
      updateProgress({
        stage: 'finalizing',
        progress: 100,
        currentFrame: (isOpfsMode ? totalOpfsFrames : totalFrames),
        totalFrames: (isOpfsMode ? totalOpfsFrames : totalFrames),
        fileSize: info.bytes
      })

      return { savedToOpfs: { dirId: (options as any).opfsDirId, fileName: info.fileName, bytesWritten: info.bytes } }
    } else {
      const buffer = output.target.buffer
      if (!buffer) {
        throw new Error('Mediabunny è¾“å‡ºç¼“å†²åŒºä¸ºç©ºï¼Œå¯èƒ½ç¼–ç è¿‡ç¨‹å¤±è´¥')
      }

      if (buffer.byteLength === 0) {
        throw new Error('Mediabunny è¾“å‡ºç¼“å†²åŒºå¤§å°ä¸º 0ï¼Œç¼–ç å¯èƒ½å¤±è´¥')
      }

      const mp4Blob = new Blob([buffer], { type: 'video/mp4' })

      // ğŸ”§ éªŒè¯ç”Ÿæˆçš„ MP4 æ–‡ä»¶


      const validation = validateMP4Blob(mp4Blob, addedFrames, totalFrames)

      if (!validation.isValid) {
        console.warn('âš ï¸ [MP4-Export-Worker] MP4 validation failed, but continuing with export')
        console.warn('âš ï¸ [MP4-Export-Worker] Validation issues:', validation.issues)
      }


      // æœ€ç»ˆè¿›åº¦
      updateProgress({
        stage: 'finalizing',
        progress: 100,
        currentFrame: (isOpfsMode ? totalOpfsFrames : totalFrames),
        totalFrames: (isOpfsMode ? totalOpfsFrames : totalFrames),
        fileSize: buffer.byteLength
      })

      return mp4Blob
    }

  } catch (error) {
    console.error('âŒ [MP4-Export-Worker] MP4 export failed:', error)
    throw new Error(`MP4 export failed: ${(error as Error).message}`)
  }
}

/**
 * è¯·æ±‚é€å¸§æ¸²æŸ“ç”¨äºå¯¼å‡º
 */
async function renderFramesForExport(videoSource: any, frameDuration: number): Promise<number> {
  if (!compositeWorker || !totalFrames) {
    throw new Error('Composite worker or frame count not available')
  }


  let addedCount = 0
  let requestErrors = 0
  let addErrors = 0

  // é€å¸§è¯·æ±‚åˆæˆå¹¶æ·»åŠ åˆ° CanvasSource
  for (let frameIndex = 0; frameIndex < totalFrames; frameIndex++) {
    if (shouldCancel) {
      break
    }

    const timestamp = frameIndex * frameDuration

    try {
      // è¯·æ±‚ composite worker æ¸²æŸ“æŒ‡å®šå¸§
      await requestCompositeFrame(frameIndex)

      // éªŒè¯ Canvas çŠ¶æ€
      if (!offscreenCanvas || !canvasCtx) {
        throw new Error(`Canvas not available for frame ${frameIndex}`)
      }

      // æ·»åŠ å½“å‰ Canvas çŠ¶æ€åˆ° CanvasSource
      try {
        await videoSource.add(timestamp, frameDuration)
        addedCount++

        if (frameIndex % 100 === 0) {
          console.log(`ğŸ“Š [MP4-Export-Worker] Progress: ${frameIndex + 1}/${totalFrames} frames, timestamp: ${timestamp.toFixed(3)}s, success rate: ${((addedCount/(frameIndex+1))*100).toFixed(1)}%`)
        }
      } catch (addError) {
        addErrors++
        console.error(`âŒ [MP4-Export-Worker] Failed to add frame ${frameIndex} to CanvasSource:`, addError)
      }

      // æ›´æ–°è¿›åº¦
      const progress = 80 + (frameIndex / totalFrames) * 15 // 80%-95%
      updateProgress({
        stage: 'muxing',
        progress,
        currentFrame: frameIndex + 1,
        totalFrames
      })

    } catch (error) {
      requestErrors++
      console.error(`âŒ [MP4-Export-Worker] Failed to process frame ${frameIndex}:`, error)
      // ç»§ç»­å¤„ç†ä¸‹ä¸€å¸§ï¼Œä¸ä¸­æ–­æ•´ä¸ªè¿‡ç¨‹
    }
  }

  // è¾“å‡ºæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯

  if (addedCount === 0) {
    console.error('âŒ [MP4-Export-Worker] CRITICAL: No frames were successfully added!')
    console.error('âŒ [MP4-Export-Worker] This indicates a serious problem with:')
    console.error('  1. Composite worker communication')
    console.error('  2. H.264 encoder availability')
    console.error('  3. Canvas state or CanvasSource configuration')
  }

  return addedCount
}

/**
 * è¯·æ±‚ composite worker æ¸²æŸ“æŒ‡å®šå¸§
 */
async function requestCompositeFrame(frameIndex: number): Promise<void> {
  return new Promise((resolve, reject) => {
    if (!compositeWorker) {
      reject(new Error('Composite worker not available'))
      return
    }

    // è®¾ç½®ä¸´æ—¶æ¶ˆæ¯å¤„ç†å™¨ç­‰å¾…å¸§æ¸²æŸ“å®Œæˆ
    const originalOnMessage = compositeWorker.onmessage
    const timeout = setTimeout(() => {
      console.error(`â° [MP4-Export-Worker] Frame ${frameIndex} rendering timeout (5s)`)
      compositeWorker!.onmessage = originalOnMessage
      reject(new Error(`Frame ${frameIndex} rendering timeout after 5 seconds`))
    }, 5000) // 5ç§’è¶…æ—¶

    compositeWorker.onmessage = (event) => {
      const { type, data } = event.data

      if (type === 'frame' && data.frameIndex === frameIndex) {
        // æ¢å¤åŸå§‹æ¶ˆæ¯å¤„ç†å™¨
        compositeWorker!.onmessage = originalOnMessage
        clearTimeout(timeout)

        // å¤„ç†æ¥æ”¶åˆ°çš„å¸§
        try {
          handleCompositeFrame(data.bitmap, data.frameIndex)
          resolve()
        } catch (handleError) {
          console.error(`âŒ [MP4-Export-Worker] Failed to handle frame ${frameIndex}:`, handleError)
          reject(handleError)
        }
      } else if (type === 'error') {
        console.error(`âŒ [MP4-Export-Worker] Composite worker error for frame ${frameIndex}:`, data)
        compositeWorker!.onmessage = originalOnMessage
        clearTimeout(timeout)
        reject(new Error(data.error || `Composite worker error for frame ${frameIndex}`))
      } else {
        // è½¬å‘å…¶ä»–æ¶ˆæ¯
        if (originalOnMessage && compositeWorker) {
          originalOnMessage.call(compositeWorker, event)
        }
      }
    }

    // è¯·æ±‚æ¸²æŸ“æŒ‡å®šå¸§
    compositeWorker.postMessage({
      type: 'seek',
      data: { frameIndex }
    })
  })
}

/**
 * æ›´æ–°è¿›åº¦
 */
function updateProgress(progress: ProgressData) {
  self.postMessage({
    type: 'progress',
    data: progress
  })
}

/**
 * å¤„ç†å–æ¶ˆè¯·æ±‚
 */
function handleCancel() {
  shouldCancel = true
  cleanup()
}

/**
 * æ¸…ç†èµ„æº
 */
function cleanup() {
  try {
    if (compositeWorker) {
      compositeWorker.terminate()
      compositeWorker = null
    }
  } catch (e) {
    console.warn('âš ï¸ [Export-Worker] Error terminating composite worker:', e)
  }

  try { cleanupOpfsReader() } catch (e) {
    console.warn('âš ï¸ [Export-Worker] Error cleaning up OPFS reader during cleanup:', e)
  }

  offscreenCanvas = null
  canvasCtx = null
  totalFrames = 0
  processedFrames = 0
  videoInfo = null
  isExporting = false
  currentExportFormat = ''
}

// Worker åˆå§‹åŒ–æ£€æŸ¥

// æ£€æŸ¥ Mediabunny åº“
const mediabunnyStatus = checkMediabunnyStatus()

// æ£€æŸ¥ OffscreenCanvas æ”¯æŒ
const hasOffscreenCanvas = typeof OffscreenCanvas !== 'undefined'

// æ£€æŸ¥ WebCodecs æ”¯æŒ
const hasWebCodecs = typeof VideoEncoder !== 'undefined'

// æµ‹è¯• H.264 å°ºå¯¸éªŒè¯

/**
 * åŸºäº OPFS çš„é€çª—å£å¸§æ¸²æŸ“ä¸æ·»åŠ 
 */
async function renderFramesForExportOpfs(videoSource: any, frameDuration: number, options: ExportOptions): Promise<number> {
  if (!compositeWorker || !totalOpfsFrames) {
    throw new Error('Composite worker or OPFS frame count not available')
  }

  let addedCount = 0

  // è‡ªé€‚åº”å›çœ‹è¾¹é™…ï¼Œåˆå§‹ä¿å®ˆï¼Œé‡åˆ°ç¼ºå£è‡ªåŠ¨å¢å¤§ï¼Œé‡åˆ°é‡å é€‚åº¦å‡å°
  let adaptiveBacktrack = Math.min(30, Math.floor(opfsWindowSize / 2))
  const maxBacktrack = Math.max(30, Math.floor(opfsWindowSize * 2 / 3))

  let nextRequestStart = 0
  // é‡ç½®å»é‡è¾¹ç•Œ
  while (nextRequestStart < totalOpfsFrames) {
    // æ‹‰å–å¹¶å¯¹é½çª—å£ï¼ˆå¯èƒ½å› å…³é”®å¸§å›é€€ï¼‰ï¼Œå¸¦å›çœ‹è¾¹é™…ä»¥é™ä½â€œç¼ºå£â€æ¦‚ç‡
    let attempts = 0
    let chunks: any[] = []
    let actualStart = 0
    let actualCount = 0
    let backtrackMargin = adaptiveBacktrack
    let requestStart = Math.max(0, nextRequestStart - backtrackMargin)
    while (true) {
      const win = await loadOpfsWindow(requestStart, opfsWindowSize)
      chunks = win.chunks
      actualStart = win.actualStart
      actualCount = win.actualCount
      if (actualCount <= 0 || chunks.length === 0) {
        console.warn('âš ï¸ [MP4-Export-Worker] Empty OPFS window, stopping. nextRequestStart=', nextRequestStart)
        break
      }
      if (actualStart > lastEmittedGlobalEnd && requestStart > 0 && adaptiveBacktrack < maxBacktrack && attempts < 2) {
        const gap = actualStart - lastEmittedGlobalEnd
        // æé«˜å›çœ‹è¾¹é™…ï¼ˆè‡³å°‘è¦†ç›–ç¼ºå£+15ï¼Œæˆ–åœ¨å½“å‰åŸºç¡€ä¸Š+10ï¼‰
        const increased = Math.max(adaptiveBacktrack + 10, gap + 15)
        const newBacktrack = Math.min(maxBacktrack, increased)
        if (newBacktrack !== adaptiveBacktrack) {
          adaptiveBacktrack = newBacktrack
        }
        backtrackMargin = adaptiveBacktrack
        requestStart = Math.max(0, nextRequestStart - backtrackMargin)
        attempts++
        continue
      }
      break
    }
    if (actualCount <= 0 || chunks.length === 0) {
      break
    }

    // å¦‚ä»å­˜åœ¨ç¼ºå£ï¼Œåˆ™ç”¨ä¸Šä¸€å¸§è¿›è¡Œâ€œä¿æŒâ€å¡«è¡¥ï¼Œé¿å…æ—¶é—´è½´è·³è¿›é€ æˆå¡é¡¿
    if (actualStart > lastEmittedGlobalEnd) {
      const gap = actualStart - lastEmittedGlobalEnd
      if (gap > 0 && addedCount > 0) {
        const fill = Math.min(gap, totalOpfsFrames - lastEmittedGlobalEnd)
        if (fill > 0) {
          console.warn(`â¯ï¸ [MP4-Export-Worker] Filling gap by holding last frame: ${fill} frame(s) (lastEnd=${lastEmittedGlobalEnd} â†’ actualStart=${actualStart})`)
          for (let i = 0; i < fill; i++) {
            const globalIndex = lastEmittedGlobalEnd + i
            const ts = globalIndex * frameDuration
            try {
              await videoSource.add(ts, frameDuration)
              addedCount++
              const progress = 80 + (globalIndex / totalOpfsFrames) * 15
              updateProgress({ stage: 'muxing', progress, currentFrame: globalIndex + 1, totalFrames: totalOpfsFrames })
            } catch (e) {
              console.warn('âš ï¸ [MP4-Export-Worker] Gap fill frame add failed:', e)
              break
            }
          }
        }
      }
      // æ— è®ºæ˜¯å¦å¡«è¡¥ï¼Œæ¨è¿› lastEmittedGlobalEnd è‡³ actualStartï¼Œåç»­æ­£å¸¸æ¸²æŸ“æ–°çª—
      lastEmittedGlobalEnd = actualStart
    }

    // åˆ‡æ¢/åˆå§‹åŒ–å½“å‰çª—å£
    await processVideoCompositionOpfs(chunks, options, actualStart)

    // å½“å‰çª—å£å†…é€å¸§æ¸²æŸ“ï¼ˆè·³è¿‡ä¸ä¸Šä¸€çª—é‡å çš„èµ·å§‹éƒ¨åˆ†ï¼‰
    const localStartIndex = Math.max(0, lastEmittedGlobalEnd - actualStart)
    if (localStartIndex > 0) {
      // å‘ç”Ÿé‡å ï¼Œé€‚åº¦å‡å°å›çœ‹ï¼Œé¿å…è¿‡åº¦å›çœ‹å¯¼è‡´çš„å†—ä½™
      adaptiveBacktrack = Math.max(10, adaptiveBacktrack - Math.min(10, localStartIndex))
    }
    if (actualStart > lastEmittedGlobalEnd) {
      const gap = actualStart - lastEmittedGlobalEnd
      console.warn(`â­ï¸ [MP4-Export-Worker] Detected gap of ${gap} frame(s) between windows (lastEnd=${lastEmittedGlobalEnd} â†’ actualStart=${actualStart}); requested with backtrack=${backtrackMargin}`)
      // å‘ç”Ÿç¼ºå£æ—¶ï¼Œæé«˜å›çœ‹è¾¹é™…ï¼ˆè‡³å°‘è¦†ç›–ç¼ºå£+15ï¼Œæˆ–åœ¨å½“å‰åŸºç¡€ä¸Š+10ï¼‰ï¼Œä¸Šé™ä¸è¶…è¿‡ 2/3 çª—å£
      const increased = Math.max(adaptiveBacktrack + 10, gap + 15)
      const newBacktrack = Math.min(maxBacktrack, increased)
      if (newBacktrack !== adaptiveBacktrack) {
        adaptiveBacktrack = newBacktrack
      }
    } else if (localStartIndex === 0 && adaptiveBacktrack > 10) {
      // è¿ç»­æ— ç¼ºå£ã€æ— é‡å æ—¶ï¼Œç¼“æ…¢è¡°å‡å›çœ‹ï¼Œé¿å…ä¸å¿…è¦çš„å›çœ‹æˆæœ¬
      adaptiveBacktrack = Math.max(10, adaptiveBacktrack - 1)
    }
    for (let localIndex = localStartIndex; localIndex < actualCount; localIndex++) {
      if (shouldCancel) {
        return addedCount
      }

      const globalIndex = actualStart + localIndex
      const timestamp = globalIndex * frameDuration

      try {
        await requestCompositeFrame(localIndex)
        await videoSource.add(timestamp, frameDuration)
        addedCount++

        // è¿›åº¦æŒ‰å…¨é‡å¸§æ•°æ±‡æŠ¥
        const progress = 80 + (globalIndex / totalOpfsFrames) * 15
        updateProgress({
          stage: 'muxing',
          progress,
          currentFrame: globalIndex + 1,
          totalFrames: totalOpfsFrames
        })

        if (globalIndex % 100 === 0) {
          console.log(`ğŸ“Š [MP4-Export-Worker] [OPFS] Progress: ${globalIndex + 1}/${totalOpfsFrames}`)
        }
      } catch (err) {
        console.error(`âŒ [MP4-Export-Worker] [OPFS] Failed to process global frame ${globalIndex}:`, err)
      }
    }

    // è·³åˆ°ä¸‹ä¸€çª—å£ï¼šä½¿ç”¨ä¸Šæ¬¡å·²è¾“å‡ºçš„å…¨å±€æœ«å°¾ï¼Œé¿å…é‡å¤ä¸å›é€€
    lastEmittedGlobalEnd = Math.max(lastEmittedGlobalEnd, actualStart + actualCount)
    nextRequestStart = lastEmittedGlobalEnd
  }

  return addedCount
}


/**
 * WebM å¯¼å‡ºï¼ˆæ”¯æŒ OPFS æµå¼å†™å…¥ï¼›å¦åˆ™èµ°å†…å­˜ BufferTargetï¼‰
 */
async function exportToWEBMCompat(options: ExportOptions): Promise<any> {
  if (!offscreenCanvas || !videoInfo) {
    throw new Error('Canvas or video info not available')
  }

  // ç¼–ç é˜¶æ®µè¿›åº¦
  updateProgress({ stage: 'encoding', progress: 75, currentFrame: 0, totalFrames: 100 })

  const strategy = new WebmStrategy()

  const useOpfsStream = Boolean((options as any)?.saveToOpfs && (options as any)?.opfsDirId)
  const { output } = await strategy.createOutput(useOpfsStream, options)

  // åˆ›å»º CanvasSourceï¼ˆvp9ï¼Œé»˜è®¤ 8Mbpsï¼‰
  const videoSource = strategy.createVideoSource(offscreenCanvas, { bitrate: options.bitrate || 8_000_000 })
  output.addVideoTrack(videoSource)

  await strategy.start(output)

  // å°è£…é˜¶æ®µè¿›åº¦
  updateProgress({ stage: 'muxing', progress: 80, currentFrame: 0, totalFrames })

  const frameRate = (options as any)?.framerate || videoInfo.frameRate
  const frameDuration = 1 / frameRate


  // é€å¸§æ¸²æŸ“å¹¶æ·»åŠ ï¼ˆOPFS æ¨¡å¼èµ°çª—å£åŒ–æ¸²æŸ“ï¼‰
  const addedFrames = isOpfsMode
    ? await renderFramesForExportOpfs(videoSource, frameDuration, options)
    : await renderFramesForExportWebm(videoSource, frameDuration)

  // å®Œæˆè¾“å‡º
  updateProgress({ stage: 'finalizing', progress: 95, currentFrame: totalFrames, totalFrames })

  await strategy.finalize(output)

  if (useOpfsStream) {
    const info = (await (strategy.getOpfsResultInfo?.(options as any) || Promise.resolve({ bytes: 0, fileName: (options as any).opfsFileName || 'export.webm' }))) as { bytes: number; fileName: string }
    updateProgress({ stage: 'finalizing', progress: 100, currentFrame: totalFrames, totalFrames, fileSize: info.bytes })
    // èµ„æºæ¸…ç†ï¼ˆæœ€ä½³åŠªåŠ›ï¼‰
    try { strategy.closeVideoSource?.(videoSource) } catch {}
    return { savedToOpfs: { dirId: (options as any).opfsDirId, fileName: info.fileName, bytesWritten: info.bytes } }
  }

  const buffer = (output as any).target?.buffer as ArrayBuffer | undefined
  if (!buffer) throw new Error('No buffer data available from Mediabunny output')

  const webmBlob = new Blob([buffer], { type: 'video/webm' })

  // æœ€ç»ˆè¿›åº¦
  updateProgress({ stage: 'finalizing', progress: 100, currentFrame: totalFrames, totalFrames, fileSize: buffer.byteLength })

  // èµ„æºæ¸…ç†ï¼ˆæœ€ä½³åŠªåŠ›ï¼‰
  try { strategy.closeVideoSource?.(videoSource) } catch {}

  return webmBlob
}

/**
 * GIF å¯¼å‡º
 * ç”±äº gif.js éœ€è¦åœ¨ä¸»çº¿ç¨‹è¿è¡Œï¼Œè¿™é‡Œæ”¶é›†æ‰€æœ‰å¸§æ•°æ®åå‘é€åˆ°ä¸»çº¿ç¨‹å¤„ç†
 */
async function exportToGIF(options: ExportOptions): Promise<Blob> {
  if (!offscreenCanvas || !videoInfo) {
    throw new Error('Canvas or video info not available')
  }


  // è·å– GIF é…ç½®
  const gifOptions = (options as any).gifOptions || {}
  const fps = gifOptions.fps || 10
  const quality = gifOptions.quality || 10
  const scale = gifOptions.scale || 1.0
  // ä»¥æºå¸§ç‡ä¸ºæ—¶é—´åŸºï¼ŒæŒ‰ gif fps æŠ½å¸§ï¼Œä¿è¯æ—¶é—´è½´ä¸€è‡´
  const sourceFps = videoInfo?.frameRate || 30
  const stride = Math.max(1, Math.round(sourceFps / fps))
  const expectedFrames = isOpfsMode ? Math.ceil(totalOpfsFrames / stride) : Math.ceil(totalFrames / stride)

  // è®¡ç®—è¾“å‡ºå°ºå¯¸
  const outputWidth = Math.floor(offscreenCanvas.width * scale)
  const outputHeight = Math.floor(offscreenCanvas.height * scale)


  // åˆ›å»º GIF ç­–ç•¥
  const gifStrategy = new GifStrategy({
    width: outputWidth,
    height: outputHeight,
    quality,
    fps,
    workers: gifOptions.workers || 2,
    repeat: gifOptions.repeat ?? 0,
    dither: gifOptions.dither || false,
    background: options.backgroundConfig?.color || '#000000',
    transparent: gifOptions.transparent || null,
    debug: gifOptions.debug || false
  })

  // ä¸åœ¨è¿™é‡Œæ›´æ–°è¿›åº¦ï¼Œå› ä¸ºåœ¨ handleExport ä¸­å·²ç»æ›´æ–°è¿‡äº†
  // é¿å…è¿›åº¦å€’é€€

  const frameDelay = 1000 / fps // æ¯«ç§’
  const targetFrameCount = isOpfsMode ? totalOpfsFrames : totalFrames


  // æ”¶é›†å¸§æ•°æ®
  const frames: GifFrameData[] = []

  if (isOpfsMode) {
    // OPFS æ¨¡å¼ï¼šçª—å£åŒ–å¤„ç†
    frames.push(...await collectFramesOpfs(gifStrategy, frameDelay, scale, stride, expectedFrames))
  } else {
    // å†…å­˜æ¨¡å¼ï¼šé€å¸§è¯·æ±‚
    frames.push(...await collectFrames(gifStrategy, frameDelay, scale, stride, expectedFrames))
  }


  // ä¸åœ¨è¿™é‡Œæ›´æ–°è¿›åº¦ï¼Œç”±ä¸»çº¿ç¨‹çš„ ExportManager ç»Ÿä¸€ç®¡ç†
  // é¿å… Worker å’Œä¸»çº¿ç¨‹åŒæ—¶æ›´æ–°å¯¼è‡´è¿›åº¦è·³å˜

  // å‘é€å¸§æ•°æ®åˆ°ä¸»çº¿ç¨‹è¿›è¡Œ GIF ç¼–ç 
  // ç”±äº gif.js éœ€è¦åœ¨ä¸»çº¿ç¨‹è¿è¡Œï¼Œæˆ‘ä»¬é€šè¿‡æ¶ˆæ¯ä¼ é€’å¸§æ•°æ®
  const gifBlob = await encodeGifInMainThread(frames, gifStrategy.getOptions())

  // æ¸…ç†
  gifStrategy.cleanup()


  // ä¸åœ¨è¿™é‡Œæ›´æ–°è¿›åº¦ï¼Œç”±ä¸»çº¿ç¨‹å®Œæˆåè‡ªç„¶è¾¾åˆ°100%

  return gifBlob
}

/**
 * æ”¶é›†å¸§æ•°æ®ï¼ˆå†…å­˜æ¨¡å¼ï¼‰
 */
async function collectFrames(
  gifStrategy: GifStrategy,
  frameDelay: number,
  scale: number,
  stride: number,
  expectedFrames: number
): Promise<GifFrameData[]> {
  const frames: GifFrameData[] = []

  for (let frameIndex = 0; frameIndex < totalFrames; frameIndex += stride) {
    if (shouldCancel) break

    try {
      // è¯·æ±‚ composite worker æ¸²æŸ“æŒ‡å®šå¸§
      await requestCompositeFrame(frameIndex)

      // æå–å¸§æ•°æ®
      if (offscreenCanvas) {
        // å¦‚æœéœ€è¦ç¼©æ”¾ï¼Œåˆ›å»ºç¼©æ”¾åçš„ canvas
        let sourceCanvas = offscreenCanvas
        if (scale !== 1.0) {
          const scaledCanvas = new OffscreenCanvas(
            Math.floor(offscreenCanvas.width * scale),
            Math.floor(offscreenCanvas.height * scale)
          )
          const scaledCtx = scaledCanvas.getContext('2d')
          if (scaledCtx) {
            scaledCtx.drawImage(offscreenCanvas, 0, 0, scaledCanvas.width, scaledCanvas.height)
            sourceCanvas = scaledCanvas
          }
        }

        const imageData = gifStrategy.extractImageData(sourceCanvas)
        frames.push({
          imageData,
          delay: frameDelay,
          dispose: 2
        })
      }

      // æ›´æ–°è¿›åº¦ï¼šå¸§æ”¶é›†é˜¶æ®µå æ€»è¿›åº¦çš„5%-40%
      const progress = 5 + (Math.min(frames.length, expectedFrames) / expectedFrames) * 35
      updateProgress({
        stage: 'encoding',
        progress,
        currentFrame: frames.length,
        totalFrames: expectedFrames
      })

    } catch (error) {
      console.error(`âŒ [GIF-Export-Worker] Failed to collect frame ${frameIndex}:`, error)
    }
  }

  return frames
}

/**
 * æ”¶é›†å¸§æ•°æ®ï¼ˆOPFS æ¨¡å¼ï¼‰
 */
async function collectFramesOpfs(
  gifStrategy: GifStrategy,
  frameDelay: number,
  scale: number,
  stride: number,
  expectedFrames: number
): Promise<GifFrameData[]> {
  const frames: GifFrameData[] = []
  let nextRequestStart = 0

  while (nextRequestStart < totalOpfsFrames) {
    if (shouldCancel) break

    // åŠ è½½çª—å£
    const { chunks, actualStart, actualCount } = await loadOpfsWindow(nextRequestStart, opfsWindowSize)

    if (actualCount <= 0 || chunks.length === 0) {
      console.warn('âš ï¸ [GIF-Export-Worker] Empty OPFS window, stopping')
      break
    }

    // å¤„ç†çª—å£
    await processVideoCompositionOpfs(chunks, { backgroundConfig: currentBackgroundConfig } as any, actualStart)

    // æå–çª—å£ä¸­çš„å¸§
    for (let i = 0; i < actualCount; i++) {
      const globalFrameIndex = actualStart + i

      if (globalFrameIndex >= totalOpfsFrames) break
      if (shouldCancel) break

      try {
        // æŒ‰æ­¥é•¿æŠ½å¸§ï¼šä»…åœ¨æ»¡è¶³å…¨å±€ç´¢å¼•å¯¹é½æ—¶é‡‡æ ·
        if (stride > 1 && (globalFrameIndex % stride) !== 0) {
          continue
        }
        // è¯·æ±‚æ¸²æŸ“å¸§
        await requestCompositeFrame(i)

        // æå–å¸§æ•°æ®
        if (offscreenCanvas) {
          let sourceCanvas = offscreenCanvas
          if (scale !== 1.0) {
            const scaledCanvas = new OffscreenCanvas(
              Math.floor(offscreenCanvas.width * scale),
              Math.floor(offscreenCanvas.height * scale)
            )
            const scaledCtx = scaledCanvas.getContext('2d')
            if (scaledCtx) {
              scaledCtx.drawImage(offscreenCanvas, 0, 0, scaledCanvas.width, scaledCanvas.height)
              sourceCanvas = scaledCanvas
            }
          }

          const imageData = gifStrategy.extractImageData(sourceCanvas)
          frames.push({
            imageData,
            delay: frameDelay,
            dispose: 2
          })
        }

        // æ›´æ–°è¿›åº¦ï¼šå¸§æ”¶é›†é˜¶æ®µå æ€»è¿›åº¦çš„5%-40%
        const progress = 5 + (Math.min(frames.length, expectedFrames) / expectedFrames) * 35
        updateProgress({
          stage: 'encoding',
          progress,
          currentFrame: frames.length,
          totalFrames: expectedFrames
        })

      } catch (error) {
        console.error(`âŒ [GIF-Export-Worker] Failed to collect OPFS frame ${globalFrameIndex}:`, error)
      }
    }

    nextRequestStart += actualCount
  }

  return frames
}

/**
 * åœ¨ä¸»çº¿ç¨‹ä¸­ç¼–ç  GIFï¼ˆæµå¼å¤„ç†ï¼‰
 * é€å¸§å‘é€æ•°æ®ä»¥é¿å…å†…å­˜æº¢å‡º
 */
async function encodeGifInMainThread(
  frames: GifFrameData[],
  options: any
): Promise<Blob> {
  return new Promise((resolve, reject) => {
    let currentFrameIndex = 0

    const handler = (event: MessageEvent) => {
      const { type, data } = event.data

      if (type === 'gif-encoder-ready') {
        // ç¼–ç å™¨å·²å‡†å¤‡å¥½ï¼Œå¼€å§‹å‘é€å¸§
        sendNextFrame()

      } else if (type === 'gif-frame-added') {
        // å¸§å·²æ·»åŠ ï¼Œå‘é€ä¸‹ä¸€å¸§
        currentFrameIndex++
        // è¿›åº¦å·²ç»åœ¨ä¸»çº¿ç¨‹çš„ ExportManager ä¸­æ›´æ–°ï¼Œè¿™é‡Œä¸é‡å¤æ›´æ–°
        sendNextFrame()

      } else if (type === 'gif-encode-complete') {
        // ç¼–ç å®Œæˆ
        self.removeEventListener('message', handler)
        resolve(data.blob)

      } else if (type === 'gif-encode-error') {
        // ç¼–ç å¤±è´¥
        self.removeEventListener('message', handler)
        reject(new Error(data.error || 'GIF encoding failed'))

      } else if (type === 'gif-encode-progress') {
        // è¿›åº¦æ›´æ–°å·²ç»åœ¨ä¸»çº¿ç¨‹å¤„ç†ï¼Œè¿™é‡Œåªè®°å½•æ—¥å¿—
      }
    }

    function sendNextFrame() {
      if (currentFrameIndex < frames.length) {
        const frame = frames[currentFrameIndex]

        // å‘é€å•å¸§æ•°æ®
        self.postMessage({
          type: 'gif-add-frame',
          data: {
            imageData: frame.imageData,
            delay: frame.delay,
            dispose: frame.dispose,
            frameIndex: currentFrameIndex,
            totalFrames: frames.length
          }
        })
      } else {
        // æ‰€æœ‰å¸§å·²å‘é€ï¼Œè¯·æ±‚æ¸²æŸ“
        self.postMessage({
          type: 'gif-render',
          data: {
            totalFrames: frames.length  // æ·»åŠ æ€»å¸§æ•°ä¿¡æ¯
          }
        })
      }
    }

    self.addEventListener('message', handler)

    // åˆå§‹åŒ–ç¼–ç å™¨
    self.postMessage({
      type: 'gif-init',
      data: {
        options,
        totalFrames: frames.length
      }
    })

    // è®¾ç½®è¶…æ—¶
    setTimeout(() => {
      self.removeEventListener('message', handler)
      reject(new Error('GIF encoding timeout'))
    }, 300000) // 5åˆ†é’Ÿè¶…æ—¶
  })
}

/**
 * WebM é€å¸§æ¸²æŸ“
 */
async function renderFramesForExportWebm(videoSource: any, frameDuration: number): Promise<void> {
  if (!compositeWorker || !totalFrames) {
    throw new Error('Composite worker or frame count not available')
  }


  for (let frameIndex = 0; frameIndex < totalFrames; frameIndex++) {
    if (shouldCancel) break

    const timestamp = frameIndex * frameDuration

    try {
      await requestCompositeFrame(frameIndex)

      await videoSource.add(timestamp, frameDuration)

      const progress = 80 + (frameIndex / totalFrames) * 15 // 80%-95%
      updateProgress({ stage: 'muxing', progress, currentFrame: frameIndex + 1, totalFrames })

      if (frameIndex % 100 === 0) {
        console.log(`ğŸ“Š [WebM-Export-Worker] Added frame ${frameIndex + 1}/${totalFrames}, ts: ${timestamp.toFixed(3)}s`)
      }
    } catch (error) {
      console.error(`âŒ [WebM-Export-Worker] Failed to add frame ${frameIndex}:`, error)
      // ä¸ä¸­æ–­æ•´ä¸ªè¿‡ç¨‹
    }
  }

}
