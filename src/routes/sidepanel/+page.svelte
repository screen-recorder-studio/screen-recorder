<script lang="ts">
  import { onMount, onDestroy } from 'svelte'
  import { TriangleAlert } from '@lucide/svelte'

  // å¼•å…¥ Worker ç³»ç»Ÿ
  import { recordingService } from '$lib/services/recording-service'
  import { recordingStore } from '$lib/stores/recording.svelte'
  import RecordButton from '$lib/components/RecordButton.svelte'
  import ElementRegionSelector from '$lib/components/ElementRegionSelector.svelte'
  import { elementRecordingIntegration, type ElementRecordingData } from '$lib/utils/element-recording-integration'
  import { recordingCache } from '$lib/services/recording-cache'
  import { recordingModeStore } from '$lib/stores/recording-mode.svelte'
  import { sendToBackground } from '$lib/utils/background'

  // å½•åˆ¶çŠ¶æ€
  let isRecording = $state(false)
  let status = $state<'idle' | 'requesting' | 'recording' | 'stopping' | 'error'>('idle')
  let errorMessage = $state('')

  // å½•åˆ¶ç›¸å…³å˜é‡
  let mediaRecorder: MediaRecorder | null = null
  let recordedChunks: Blob[] = []
  let stream: MediaStream | null = null


  // Worker ç³»ç»ŸçŠ¶æ€
  let workerSystemReady = $state(false)
  let workerEnvironmentIssues = $state<string[]>([])


  // Worker å½•åˆ¶æ•°æ®æ”¶é›†
  let workerEncodedChunks = $state<any[]>([])
  let workerCurrentWorker: Worker | null = null



  // ========= OPFS Writer (feature-flagged) =========
  const OPFS_WRITER_ENABLED = true // set true to enable OPFS side-write (dev only)
  let opfsWriter: Worker | null = null
  let opfsWriterReady = false
  let opfsSessionId: string | null = null
  let lastWorkerConfiguredConfig: any = null

  function ensureOpfsSessionId() {
    if (!opfsSessionId) opfsSessionId = `${Date.now()}`
    return opfsSessionId
  }

  async function initOpfsWriter(meta: { codec?: string; width?: number; height?: number; fps?: number }) {
    if (!OPFS_WRITER_ENABLED) return
    try {
      if (opfsWriter) return
      opfsWriterReady = false
      opfsWriter = new Worker(
        new URL('../../lib/workers/opfs-writer-worker.ts', import.meta.url),
        { type: 'module' }
      )
      const id = ensureOpfsSessionId()
      opfsWriter.onmessage = (ev: MessageEvent) => {
        const { type, id: rid } = ev.data || {}
        if (type === 'ready') {
          console.log('[OPFS] writer ready for', rid)
          opfsWriterReady = true
        } else if (type === 'progress') {
          const { bytesWrittenTotal, chunksWritten } = ev.data
          if (chunksWritten % 200 === 0) console.log('[OPFS] progress', { bytesWrittenTotal, chunksWritten })
        } else if (type === 'error') {
          console.warn('[OPFS] writer error', ev.data)
        } else if (type === 'finalized') {
          console.log('[OPFS] writer finalized for', rid)
        }
      }
      opfsWriter.postMessage({ type: 'init', id, meta })
    } catch (e) {
      console.warn('[OPFS] init failed (feature disabled or env unsupported):', e)
      opfsWriter = null
      opfsWriterReady = false
    }
  }

  function appendToOpfsFromEncodedChunk(d: { data: Uint8Array; timestamp?: number; type?: string; codedWidth?: number; codedHeight?: number; codec?: string }) {
    if (!OPFS_WRITER_ENABLED || !opfsWriter || !opfsWriterReady) return
    try {
      // Do NOT transfer the same buffer because we still need it for IndexedDB handoff
      const copy = new Uint8Array(d.data.byteLength)
      copy.set(d.data)
      opfsWriter.postMessage({
        type: 'append',
        buffer: copy.buffer,
        timestamp: d.timestamp || 0,
        chunkType: d.type === 'key' ? 'key' : 'delta',
        codedWidth: d.codedWidth,
        codedHeight: d.codedHeight,
        codec: d.codec,
        isKeyframe: d.type === 'key'
      }, [copy.buffer])
    } catch (e) {
      console.warn('[OPFS] append failed', e)
    }
  }

  async function finalizeOpfsWriter() {
    if (!OPFS_WRITER_ENABLED || !opfsWriter) return
    const writer = opfsWriter
    try {
      await new Promise<void>((resolve) => {
        let settled = false
        const onMsg = (ev: MessageEvent) => {
          const t = (ev.data || {}).type
          if (t === 'finalized' || t === 'error') {
            if (!settled) { settled = true; try { writer.removeEventListener('message', onMsg as any) } catch {}; resolve() }
          }
        }
        try { writer.addEventListener('message', onMsg as any) } catch {}
        try { writer.postMessage({ type: 'finalize' }) } catch {}
        // safety timeout
        setTimeout(() => { if (!settled) { settled = true; try { writer.removeEventListener('message', onMsg as any) } catch {}; resolve() } }, 1500)
      })
    } catch (e) {
      console.warn('[OPFS] finalize failed', e)
    } finally {
      try { writer.terminate() } catch {}
      if (opfsWriter === writer) { opfsWriter = null; opfsWriterReady = false; opfsSessionId = null }
    }
  }


	  // è·³è½¬æç¤º
	  let showHandoffNotice = $state(false)
	  let handoffText = $state('å°†è½¬åˆ° Studio ä¸­...')


	  // é¿å…é‡å¤è§¦å‘ handoff çš„ä¿æŠ¤æ ‡è®°
	  let handoffInProgress = $state(false)


  // Worker ç³»ç»Ÿçš„è®¡ç®—å±æ€§
  const workerIsRecording = $derived(recordingStore.isRecording)
  const workerStatus = $derived(recordingStore.state.status)
  const workerErrorMessage = $derived(recordingStore.state.error)


  // Worker ç³»ç»Ÿå‡½æ•° - æ­£ç¡®çš„ WebCodecs æ¶æ„
  async function startWorkerRecording() {
    try {
      console.log('ğŸ¬ [WORKER-MAIN] Starting Worker recording with WebCodecs...')

      // 1. è·å–åª’ä½“æµï¼ˆä¸»çº¿ç¨‹ï¼‰
      console.log('ğŸ“º [WORKER-MAIN] Step 1: Requesting desktop capture...')
      const streamId = await requestDesktopCapture()
      if (!streamId) {
        throw new Error('DESKTOP_CAPTURE_CANCELLED')
      }
      console.log('âœ… [WORKER-MAIN] Desktop capture granted, streamId:', streamId)

      console.log('ğŸ¥ [WORKER-MAIN] Step 2: Getting MediaStream from streamId...')
      const stream = await getUserMediaFromStreamId(streamId)
      if (!stream) {
        throw new Error('æ— æ³•è·å–åª’ä½“æµ')
      }
      console.log('âœ… [WORKER-MAIN] MediaStream obtained:', {
        id: stream.id,
        active: stream.active,
        videoTracks: stream.getVideoTracks().length,
        audioTracks: stream.getAudioTracks().length
      })

      // 2. æ£€æŸ¥ WebCodecs æ”¯æŒ
      console.log('âœ… [WORKER-MAIN] VideoEncoder available')

      // 3. åˆ›å»º MediaStreamTrackProcessorï¼ˆä¸»çº¿ç¨‹ï¼‰
      console.log('ğŸï¸ [WORKER-MAIN] Step 4: Creating MediaStreamTrackProcessor...')
      const videoTrack = stream.getVideoTracks()[0]
      if (!videoTrack) {
        throw new Error('No video track found')
      }
      console.log('âœ… [WORKER-MAIN] Video track found:', {
        id: videoTrack.id,
        kind: videoTrack.kind,
        label: videoTrack.label,
        enabled: videoTrack.enabled,
        readyState: videoTrack.readyState
      })

      console.log('âœ… [WORKER-MAIN] MediaStreamTrackProcessor available')

      const processor = new MediaStreamTrackProcessor({ track: videoTrack })
      const reader = processor.readable.getReader()
      console.log('âœ… [WORKER-MAIN] MediaStreamTrackProcessor created and reader obtained')

      // 4. åˆ›å»º Worker è¿›è¡Œ WebCodecs ç¼–ç 
      console.log('ğŸ‘· [WORKER-MAIN] Step 5: Creating WebCodecs Worker...')
      const worker = new Worker(
        new URL('../../lib/workers/webcodecs-worker.ts', import.meta.url),
        { type: 'module' }
      )
      console.log('âœ… [WORKER-MAIN] Worker created successfully')

      // 5. ç­‰å¾… Worker é…ç½®å®Œæˆçš„ Promise
      let workerConfigured = false
      let workerInitialized = false

      const workerReadyPromise = new Promise<void>((resolve, reject) => {
        const timeout = setTimeout(() => {
          console.error('âŒ [WORKER-MAIN] Worker configuration timeout after 10 seconds')
          console.error('âŒ [WORKER-MAIN] Worker initialized:', workerInitialized)
          console.error('âŒ [WORKER-MAIN] Worker configured:', workerConfigured)
          reject(new Error('Worker configuration timeout'))
        }, 10000) // 10ç§’è¶…æ—¶

        worker.onmessage = (event) => {
          console.log('ğŸ“¨ [WORKER-MAIN] Received Worker message during setup:', event.data)

          if (event.data.type === 'initialized') {
            console.log('âœ… [WORKER-MAIN] Worker initialized successfully')
            workerInitialized = true
          } else if (event.data.type === 'configured') {
            console.log('âœ… [WORKER-MAIN] Worker configuration confirmed')
            workerConfigured = true
            // ä¿å­˜å®é™…é…ç½®ï¼Œå¹¶åœ¨æ­¤æ—¶åˆå§‹åŒ– OPFS å†™å…¥ï¼ˆé¿å…åç»­ handler é”™è¿‡ configured äº‹ä»¶ï¼‰
            const cfg = event.data.config
            lastWorkerConfiguredConfig = cfg
            if (OPFS_WRITER_ENABLED) {
              try {
                initOpfsWriter({
                  codec: cfg?.codec,
                  width: cfg?.width,
                  height: cfg?.height,
                  fps: cfg?.framerate
                })
              } catch (e) {
                console.warn('[OPFS] init during setup failed:', e)
              }
            }
            clearTimeout(timeout)
            resolve()
            // é…ç½®å®Œæˆåï¼Œè®¾ç½®æ­£å¸¸çš„æ¶ˆæ¯å¤„ç†å™¨
            setupWorkerMessageHandler(worker)
          } else if (event.data.type === 'error') {
            console.error('âŒ [WORKER-MAIN] Worker error during setup:', event.data.data)
            clearTimeout(timeout)
            reject(new Error(`Worker setup error: ${event.data.data}`))
          }
        }

        worker.onerror = (error) => {
          console.error('âŒ [WORKER-MAIN] Worker error event during setup:', error)
          clearTimeout(timeout)
          reject(new Error(`Worker error: ${error.message || 'Unknown error'}`))
        }
      })

      // 6. é…ç½® Worker
      // ä¾æ®é‡‡é›†è½¨é“çš„è‡ªç„¶å°ºå¯¸é…ç½®ç¼–ç å™¨ï¼Œé¿å…æ‹‰ä¼¸å˜å½¢
      const trackSettings = videoTrack.getSettings ? videoTrack.getSettings() : {}
      console.log('ğŸ“ [WORKER-MAIN] Track settings:', trackSettings)

      // æ›´å¯é çš„å°ºå¯¸è·å–ç­–ç•¥
      let encoderWidth = 1920
      let encoderHeight = 1080

      // ç­–ç•¥1: ä» track settings è·å–
      if (trackSettings?.width && trackSettings?.height) {
        encoderWidth = trackSettings.width
        encoderHeight = trackSettings.height
        console.log('âœ… [WORKER-MAIN] Using track settings dimensions:', { encoderWidth, encoderHeight })
      } else {
        // ç­–ç•¥2: ä» track constraints è·å–
        const constraints = videoTrack.getConstraints ? videoTrack.getConstraints() : {}
        console.log('ğŸ“ [WORKER-MAIN] Track constraints:', constraints)

        if (constraints?.width && constraints?.height) {
          encoderWidth = typeof constraints.width === 'object' ? constraints.width.ideal || constraints.width.max || 1920 : constraints.width
          encoderHeight = typeof constraints.height === 'object' ? constraints.height.ideal || constraints.height.max || 1080 : constraints.height
          console.log('âœ… [WORKER-MAIN] Using track constraints dimensions:', { encoderWidth, encoderHeight })
        } else {
          console.warn('âš ï¸ [WORKER-MAIN] No reliable dimensions found, using defaults:', { encoderWidth, encoderHeight })
        }
      }

      // éªŒè¯å°ºå¯¸åˆç†æ€§
      if (encoderWidth < 100 || encoderHeight < 100 || encoderWidth > 7680 || encoderHeight > 4320) {
        console.warn('âš ï¸ [WORKER-MAIN] Invalid dimensions detected, using safe defaults')
        encoderWidth = 1920
        encoderHeight = 1080
      }

      const encoderFps = Math.round(trackSettings?.frameRate || 30)

      const workerConfig = {
        codec: 'vp9',
        width: encoderWidth,
        height: encoderHeight,
        bitrate: 8000000,
        framerate: encoderFps
      }
      console.log('âš™ï¸ [WORKER-MAIN] Step 6: Configuring Worker with:', workerConfig)
      worker.postMessage({
        type: 'configure',
        config: workerConfig
      })

      // 7. ç­‰å¾…é…ç½®å®Œæˆ
      console.log('â³ [WORKER-MAIN] Waiting for Worker configuration...')
      await workerReadyPromise
      console.log('âœ… [WORKER-MAIN] Worker is ready for encoding!')

      // 8. ä¼ é€’ VideoFrame åˆ° Workerï¼ˆåªåœ¨é…ç½®å®Œæˆåï¼‰
      let frameCount = 0
      const processFrames = async () => {
        try {
          console.log('ğŸï¸ [WORKER-MAIN] Step 8: Starting frame processing loop...')

          // ç¡®ä¿ Worker å·²é…ç½®
          if (!workerConfigured) {
            console.warn('âš ï¸ [WORKER-MAIN] Worker not configured yet, waiting...')
            await workerReadyPromise
          }

          console.log('âœ… [WORKER-MAIN] Worker is ready, starting frame processing')

          // ä¸å…ƒç´ /åŒºåŸŸå½•åˆ¶ä¸€è‡´ï¼šé¦–å¸§ + æ¯ 2 ç§’å…³é”®å¸§
          let frameIndex = 0
          while (true) {
            const { done, value: frame } = await reader.read()
            if (done) {
              console.log('ğŸ [WORKER-MAIN] Frame reading completed, total frames:', frameCount)
              // é€šçŸ¥ Worker åœæ­¢ç¼–ç 
              worker.postMessage({ type: 'stop' })
              break
            }

            // ç»Ÿè®¡å¸§
            frameCount++
            if (frameCount % 30 === 0) { // æ¯ç§’æ—¥å¿—ä¸€æ¬¡ï¼ˆå‡è®¾30fpsï¼‰
              console.log(`ğŸ“Š [WORKER-MAIN] Processing frame ${frameCount}, timestamp: ${frame.timestamp}`)
            }

            // å…³é”®å¸§ç­–ç•¥ï¼šé¦–å¸§æˆ–æ¯ 2 ç§’å¼ºåˆ¶å…³é”®å¸§
            const keyFrame = frameIndex === 0 || (frameIndex % (encoderFps * 2) === 0)

            // ä¼ é€’ VideoFrame åˆ° Workerï¼ˆTransferable Objectï¼‰
            worker.postMessage({
              type: 'encode',
              frame: frame,
              keyFrame
            }, [frame])

            frameIndex++
          }
        } catch (error) {
          console.error('âŒ [WORKER-MAIN] Frame processing error:', error)
        }
      }

      // 7. è®¾ç½® Worker æ¶ˆæ¯å¤„ç†å™¨çš„å‡½æ•°
      function setupWorkerMessageHandler(worker: Worker) {
        console.log('ğŸ“¡ [WORKER-MAIN] Setting up Worker message listener...')
        worker.onmessage = (event) => {
          const { type, data, config } = event.data
          console.log(`ğŸ“¨ [WORKER-MAIN] Received message from Worker:`, { type, data: data ? 'present' : 'none' })

          switch (type) {
            case 'configured':
              console.log('âœ… [WORKER-MAIN] Worker configured successfully:', config)
              // Store actual configured config from worker
              lastWorkerConfiguredConfig = config
              // Initialize OPFS writer (feature-flagged)
              if (OPFS_WRITER_ENABLED) {
                initOpfsWriter({
                  codec: config?.codec,
                  width: config?.width,
                  height: config?.height,
                  fps: config?.framerate
                })
              }
              break
            case 'chunk':
              // å¤„ç†ç¼–ç åçš„æ•°æ®å—
              console.log(`ğŸ“¦ [WORKER-MAIN] Received encoded chunk:`, {
                size: data.size,
                timestamp: data.timestamp,
                type: data.type,
                totalChunks: data.totalChunks
              })

              // æ”¶é›†ç¼–ç æ•°æ®å—
              if (data.data) {
                workerEncodedChunks.push({
                  data: data.data,
                  timestamp: data.timestamp,
                  type: data.type,
                  size: data.size,
                  // æ·»åŠ åˆ†è¾¨ç‡ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                  codedWidth: data.codedWidth || 1920,
                  codedHeight: data.codedHeight || 1080
                })
                console.log(`ğŸ’¾ [WORKER-MAIN] Collected chunk ${workerEncodedChunks.length}, total size: ${workerEncodedChunks.reduce((sum, chunk) => sum + chunk.size, 0)} bytes`)
                // Side-write to OPFS (does not transfer the same buffer)
                try { appendToOpfsFromEncodedChunk(data) } catch {}
              }
              break
            case 'complete':
              // å½•åˆ¶å®Œæˆ
              console.log('ğŸ‰ [WORKER-MAIN] Worker recording completed successfully!')
              break
            case 'error':
              console.error('âŒ [WORKER-MAIN] Worker encoding error:', data)
              workerEnvironmentIssues = [data || 'Worker ç¼–ç é”™è¯¯']
              break
            default:
              console.warn('âš ï¸ [WORKER-MAIN] Unknown message type from Worker:', type)
          }
        }

        // Worker é”™è¯¯å¤„ç†
        worker.onerror = (error) => {
          console.error('âŒ [WORKER-MAIN] Worker error:', error)
          workerEnvironmentIssues = ['Worker è¿è¡Œé”™è¯¯']
        }
      }

      // 9. å¼€å§‹å¤„ç†å¸§
      console.log('ğŸš€ [WORKER-MAIN] Step 9: Starting frame processing...')

      // åˆå§‹åŒ–å½•åˆ¶çŠ¶æ€
      workerEncodedChunks = [] // æ¸…ç©ºä¹‹å‰çš„æ•°æ®
      workerCurrentWorker = worker

      // æ›´æ–°å½•åˆ¶çŠ¶æ€åˆ° storeï¼ˆè¿™æ ·UIä¼šæ›´æ–°ï¼‰
      recordingStore.updateStatus('recording')
      recordingStore.setEngine('webcodecs')

      processFrames()

      workerSystemReady = true
      console.log('ğŸ‰ [WORKER-MAIN] âœ… Worker recording started successfully with WebCodecs!')
      console.log('ğŸ“Š [WORKER-MAIN] System status: Ready for high-performance recording')

    } catch (error) {
      console.error('âŒ [WORKER-MAIN] Worker recording failed:', error)
      workerEnvironmentIssues = [(error as Error).message || 'å½•åˆ¶å¤±è´¥']
    }
  }


  async function stopWorkerRecording() {
    try {
      console.log('ğŸ›‘ Stopping Worker recording...')

      // åœæ­¢ Worker å½•åˆ¶
      if (workerCurrentWorker) {
        workerCurrentWorker.postMessage({ type: 'stop' })
      }

      // æ›´æ–°å½•åˆ¶çŠ¶æ€
      recordingStore.updateStatus('stopping')

      // å¤„ç†æ”¶é›†åˆ°çš„ç¼–ç æ•°æ®
      console.log(`ğŸ“Š [WORKER-MAIN] Recording stopped. Collected ${workerEncodedChunks.length} chunks`)
      const totalSize = workerEncodedChunks.reduce((sum, chunk) => sum + chunk.size, 0)
      console.log(`ğŸ“Š [WORKER-MAIN] Total encoded data size: ${(totalSize / 1024 / 1024).toFixed(2)} MB`)

      if (workerEncodedChunks.length > 0) {
        try {
          // æ ‡è®°å®ŒæˆçŠ¶æ€
          recordingStore.updateStatus('completed')

          // æ˜¾ç¤ºè·³è½¬æç¤º
          console.log('ğŸ”„ [WORKER-MAIN] å½•åˆ¶å®Œæˆï¼Œæ­£åœ¨ä¿å­˜å¹¶è·³è½¬åˆ° Studio...')

          // è‡ªåŠ¨è·³è½¬åˆ° Studio
          await openInStudio()
        } catch (error) {
          console.error('âŒ Failed to handoff to Studio page:', error)
        }
      } else {
        console.warn('âš ï¸ No encoded chunks to save')
        recordingStore.updateStatus('error', 'No encoded chunks to save')
      }

      // æ¸…ç† Worker å¼•ç”¨
      workerCurrentWorker = null


	      // Finalize OPFS writer if enabled
	      await finalizeOpfsWriter()

    } catch (error) {
      console.error('âŒ Worker stop failed:', error)
    }
  }

  async function checkWorkerEnvironment() {
    try {
      const env = await recordingService.checkEnvironment()
      workerSystemReady = env.isReady
      workerEnvironmentIssues = env.issues
      console.log('ğŸ” Worker environment check:', env)
      return env.isReady
    } catch (error) {
      console.error('âŒ Worker environment check failed:', error)
      workerSystemReady = false
      workerEnvironmentIssues = ['Worker ç¯å¢ƒæ£€æŸ¥å¤±è´¥']
      return false
    }
  }

  // å¤„ç†å…ƒç´ å½•åˆ¶æ•°æ®
  async function handleElementRecordingData(message: any) {
    try {

      if (!message.encodedChunks || message.encodedChunks.length === 0) {
        console.warn('âš ï¸ [Sidepanel] No encoded chunks in element recording data')
        return
      }

      // éªŒè¯æ•°æ®æ ¼å¼
      const firstChunk = message.encodedChunks[0];
      if (!Array.isArray(firstChunk.data)) {
        console.warn('âš ï¸ [Sidepanel] Unexpected data format, expected array');
      }

      // é¢„æ ‡å‡†åŒ–ï¼šç¡®ä¿ chunk.data ä¸º Uint8Arrayã€è¡¥å…¨å°ºå¯¸/æ—¶é—´æˆ³
      const normalizedMeta = {
        ...(message.metadata || {}),
        mode: (message.metadata?.mode) || (message.metadata?.selectedRegion ? 'region' : 'element'),
        source: (message.metadata?.source) || 'element-recording'
      };
      const normalizedChunks = (message.encodedChunks || []).map((c: any) => {
        let data: any = c?.data;
        if (!(data instanceof Uint8Array)) {
          if (data instanceof ArrayBuffer) data = new Uint8Array(data);
          else if (Array.isArray(data)) data = new Uint8Array(data);
          else data = new Uint8Array(0);
        }
        const size = (typeof c?.size === 'number' && c.size > 0) ? c.size : (data?.byteLength || 0);
        const ts = (typeof c?.timestamp === 'number') ? c.timestamp : 0;
        return {
          data,
          timestamp: ts,
          type: c?.type === 'key' ? 'key' : 'delta',
          size,
          codedWidth: normalizedMeta.selectedRegion?.width,
          codedHeight: normalizedMeta.selectedRegion?.height,
          codec: c?.codec || normalizedMeta.codec || 'vp8'
        };
      });

      // ä½¿ç”¨é›†æˆå·¥å…·å¤„ç†æ•°æ®ï¼ˆå·²æ ‡å‡†åŒ–ï¼‰
      const recordingData: ElementRecordingData = {
        encodedChunks: normalizedChunks,
        metadata: normalizedMeta
      }

      // é€šè¿‡é›†æˆå·¥å…·å¤„ç†
      elementRecordingIntegration.handleRecordingData(recordingData)

      // å°†å…ƒç´ å½•åˆ¶æ•°æ®è®¾ç½®åˆ°ä¸»ç³»ç»Ÿ
      workerEncodedChunks = recordingData.encodedChunks

	    try {
        console.log('[Handoff][Sidepanel] calling openInStudio with chunks', workerEncodedChunks?.length)

        await openInStudio()
      } catch (e) {
        console.error('\u274c [Sidepanel] Auto handoff to Studio failed:', e)
      }

      // æ›´æ–°å½•åˆ¶çŠ¶æ€ä¸ºå®Œæˆ
      recordingStore.updateStatus('completed')
      recordingStore.setEngine('webcodecs')

      console.log('âœ… [Sidepanel] Element recording data integrated successfully')

      // æ˜¾ç¤ºæˆåŠŸé€šçŸ¥
      const summary = elementRecordingIntegration.getRecordingSummary(recordingData)
      showIntegrationNotification(message.metadata, summary)

    } catch (error) {
      console.error('âŒ [Sidepanel] Error handling element recording data:', error)
    }
  }

  // å¤„ç†å…ƒç´ å½•åˆ¶å°±ç»ªé€šçŸ¥
  function handleElementRecordingReady(data: any) {
    try {
      console.log('ğŸ¬ [Sidepanel] Element recording ready notification:', data)

      if (data?.encodedChunks) {
        handleElementRecordingData(data)
      }
    } catch (error) {
      console.error('âŒ [Sidepanel] Error handling element recording ready:', error)
    }
  }

  // å°†å½“å‰å½•åˆ¶æ•°æ®ä¿å­˜å¹¶åœ¨æ–°æ ‡ç­¾æ‰“å¼€ Studio é¡µé¢
  async function openInStudio() {
    try {
      console.log('[Handoff][Sidepanel] openInStudio entered', { chunks: workerEncodedChunks?.length, handoffInProgress })
      if (!workerEncodedChunks || workerEncodedChunks.length === 0) {
        console.warn('âš ï¸ [Sidepanel] No chunks to handoff to Studio')
        return
      }
      if (handoffInProgress) {
        console.warn('â³ [Sidepanel] Handoff already in progress', { chunks: workerEncodedChunks?.length })
        return
      }
      handoffInProgress = true
      const totalSize = workerEncodedChunks.reduce((s, c) => s + (c.size || 0), 0)
      const first = workerEncodedChunks[0] || {}
      // Use OPFS session ID when available to keep Studio URL consistent with OPFS directory
      let id = `rec_${Date.now()}`
      if (OPFS_WRITER_ENABLED && opfsSessionId) {
        id = `rec_${opfsSessionId}`
      }
      const meta = {
        width: first.codedWidth || 1920,
        height: first.codedHeight || 1080,
        fps: 30,
        codec: first.codec || 'vp9',
        engine: 'webcodecs',
        totalChunks: workerEncodedChunks.length,
        totalSize
      }
      console.log('ğŸ’¾ [Sidepanel] Saving recording to IndexedDB...', { id, meta })

      // await recordingCache.save(id, workerEncodedChunks, meta)

      // æ‰“å¼€æ‰©å±•æ ¹ç›®å½•ä¸‹çš„ studio.htmlï¼ˆæŒ‰éœ€åŠ è½½ idï¼‰
      const targetUrl = (typeof chrome !== 'undefined' && chrome.runtime)
        ? chrome.runtime.getURL(`studio.html?id=${encodeURIComponent(id)}`)
        : `/studio.html?id=${encodeURIComponent(id)}`
      console.log('ğŸ§­ [Sidepanel] Opening Studio URL:', targetUrl)

      // æ˜¾ç¤ºâ€œå°†è½¬åˆ° Studio ä¸­...â€æç¤º
      showHandoffNotice = true

      if (typeof chrome !== 'undefined' && chrome.tabs && chrome.runtime) {
        chrome.tabs.create({ url: targetUrl }, () => {
          const err = chrome.runtime.lastError
          if (err) {
            console.error('âŒ [Sidepanel] chrome.tabs.create failed:', err.message)
            // å¤±è´¥åˆ™ä¿ç•™å½“å‰ç¼–è¾‘æ€ï¼Œæç¤ºä»æ˜¾ç¤ºç‰‡åˆ»åéšè—
            setTimeout(() => { showHandoffNotice = false; handoffInProgress = false }, 1500)
          } else {
            console.log('âœ… [Sidepanel] Studio tab opened')
            // æˆåŠŸåå¤ä½ sidepanelï¼Œé¿å…è¿›å…¥ç¼–è¾‘æ¨¡å¼
            workerEncodedChunks = []
            recordingStore.updateStatus('idle')
            showHandoffNotice = false
            handoffInProgress = false
          }
        })
      } else {
        // éæ‰©å±•ç¯å¢ƒï¼ˆå¼€å‘æ¨¡å¼ï¼‰å›é€€
        window.open(targetUrl, '_blank')
        setTimeout(() => {
          workerEncodedChunks = []
          recordingStore.updateStatus('idle')
          showHandoffNotice = false
          handoffInProgress = false
        }, 300)
      }
    } catch (e) {
      console.error('âŒ [Sidepanel] openInStudio failed:', e)
      showHandoffNotice = false
      handoffInProgress = false
    }
  }

  // æ˜¾ç¤ºé›†æˆæˆåŠŸé€šçŸ¥
  function showIntegrationNotification(metadata: any, summary?: any) {
    // è¿™é‡Œå¯ä»¥æ·»åŠ  UI é€šçŸ¥é€»è¾‘
    console.log('ğŸ‰ [Sidepanel] Element recording integrated:', {
      mode: metadata?.mode,
      element: metadata?.selectedElement,
      region: metadata?.selectedRegion,
      chunks: workerEncodedChunks.length,
      summary
    })
  }



  async function handleWorkerRecordButtonClick() {
    if (workerIsRecording) {
      await stopWorkerRecording()
    } else {
      await startWorkerRecording()
    }
  }
  // ä» ElementRegionSelector ç§»åŠ¨è¿‡æ¥çš„å½•åˆ¶å‡½æ•°
  const recording = $derived(recordingModeStore.isRecording)
  const currentMode = $derived(recordingModeStore.currentMode)

  // å½•åˆ¶æŒ‰é’®æ˜¾ç¤ºé€»è¾‘
  const shouldShowElementRecordButton = $derived(currentMode === 'element' || currentMode === 'region')
  const shouldShowWebCodecsRecordButton = $derived(currentMode === 'tab' || currentMode === 'window' || currentMode === 'screen')

  // Element/Region å½•åˆ¶ UI çŠ¶æ€ï¼ˆæ˜¾å¼å‡†å¤‡é˜¶æ®µï¼‰
  let elementUIStatus = $state<'idle' | 'requesting' | 'recording' | 'stopping' | 'error' | 'completed'>('idle')

  async function handleStartCapture() {
    // è¿›å…¥å‡†å¤‡é˜¶æ®µï¼Œå…ˆæ„å»ºå¿…è¦é€šé“/èµ„æº
    elementUIStatus = 'requesting'
    // è§¦å‘å†…å®¹è„šæœ¬çœŸæ­£å¼€å§‹é‡‡é›†
    await sendToBackground('START_CAPTURE')
  }

  async function handleStopCapture() {
    // ç»“æŸå½•åˆ¶
    elementUIStatus = 'stopping'
    await sendToBackground('STOP_CAPTURE')
    // å›åˆ°åˆå§‹çŠ¶æ€ï¼šé€€å‡ºé€‰æ‹©å¹¶æ¸…é™¤å·²é€‰
    await sendToBackground('EXIT_SELECTION')
    await sendToBackground('CLEAR_SELECTION')
    // å¤ä½ UI çŠ¶æ€
    elementUIStatus = 'idle'
  }

  async function handleToggleCapture() {
    if (recording) {
      await handleStopCapture()
    } else {
      await handleStartCapture()
    }
  }





  // å¤„ç†å½•åˆ¶é”™è¯¯
  function handleRecordingError(message: string) {
    errorMessage = message
    status = 'error'
    isRecording = false

    // æ¸…ç†èµ„æº
    cleanup()

    // 3ç§’åé‡ç½®é”™è¯¯çŠ¶æ€
    setTimeout(() => {
      if (status === 'error') {
        status = 'idle'
        errorMessage = ''
      }
    }, 3000)
  }

  // æ¸…ç†èµ„æº
  function cleanup() {
    if (mediaRecorder) {
      mediaRecorder = null
    }

    if (stream) {
      stream.getTracks().forEach(track => track.stop())
      stream = null
    }

    recordedChunks = []
  }



  // ç›´æ¥è¯·æ±‚æ¡Œé¢æ•è·
  async function requestDesktopCapture(): Promise<string> {
    return new Promise((resolve, reject) => {
      if (!chrome?.desktopCapture) {
        reject(new Error('chrome.desktopCapture API not available'))
        return
      }

      console.log('ğŸ“ Calling chrome.desktopCapture.chooseDesktopMedia...')

      // æ ¹æ®å½“å‰ç”¨æˆ·é€‰æ‹©çš„æ¨¡å¼ç¡®å®š sources
      const currentSelectedMode = recordingModeStore.currentMode
      let sources: string[]

      if (currentSelectedMode === 'tab') {
        sources = ['tab']
      } else if (currentSelectedMode === 'window') {
        sources = ['window']
      } else if (currentSelectedMode === 'screen') {
        sources = ['screen']
      } else {
        // é»˜è®¤æƒ…å†µï¼ˆelement/region æ¨¡å¼ä¸åº”è¯¥è°ƒç”¨è¿™ä¸ªå‡½æ•°ï¼Œä½†ä½œä¸ºåå¤‡ï¼‰
        sources = ['screen', 'window', 'tab']
      }

      console.log('ğŸ¯ Using sources for mode:', currentSelectedMode, 'â†’', sources)

      const requestId = chrome.desktopCapture.chooseDesktopMedia(
        sources,
        null as any, // ç±»å‹æ–­è¨€ä¿®å¤TypeScripté”™è¯¯
        (streamId, options) => {
          console.log('ğŸ“ Desktop capture callback:', { streamId, options })

          if (streamId) {
            console.log('âœ… Desktop capture granted:', streamId)
            resolve(streamId)
          } else {
            console.log('âŒ Desktop capture cancelled by user')
            reject(new Error('DESKTOP_CAPTURE_CANCELLED'))
          }
        }
      )

      console.log('ğŸ“ Desktop capture request ID:', requestId)
    })
  }

  // ä»streamIdè·å–MediaStream
  async function getUserMediaFromStreamId(streamId: string): Promise<MediaStream> {
    try {
      console.log('Getting media stream for streamId:', streamId)

      // æ£€æŸ¥navigator.mediaDevicesæ˜¯å¦å¯ç”¨
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error('navigator.mediaDevices.getUserMedia is not available')
      }

      // Chromeæ‰©å±•çš„æ­£ç¡®çº¦æŸæ ¼å¼ï¼ˆå›é€€åˆ°å·¥ä½œç‰ˆæœ¬ï¼‰
      const constraints = {
        audio: false,
        video: {
          mandatory: {
            chromeMediaSource: 'desktop',
            chromeMediaSourceId: streamId
          }
        }
      }

      console.log('Using constraints:', constraints)
      console.log('Calling navigator.mediaDevices.getUserMedia...')

      // ä½¿ç”¨ getUserMedia è·å–åª’ä½“æµ
      const stream = await navigator.mediaDevices.getUserMedia(constraints as any)

      console.log('getUserMedia returned:', stream)

      if (!stream) {
        throw new Error('Failed to get media stream')
      }

      // æ£€æŸ¥è§†é¢‘è½¨é“
      const videoTracks = stream.getVideoTracks()
      if (videoTracks.length === 0) {
        throw new Error('No video tracks found in media stream')
      }

      // æ£€æŸ¥è§†é¢‘è½¨é“çŠ¶æ€
      const videoTrack = videoTracks[0]
      if (videoTrack.readyState !== 'live') {
        throw new Error(`Video track not ready: ${videoTrack.readyState}`)
      }

      console.log('Media stream obtained successfully:', {
        id: stream.id,
        videoTracks: videoTracks.length,
        audioTracks: stream.getAudioTracks().length,
        videoTrackState: videoTrack.readyState,
        videoTrackLabel: videoTrack.label
      })

      return stream
    } catch (error) {
      console.error('Error getting media stream:', error)

      // æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
      if (error instanceof Error) {
        if (error.name === 'AbortError') {
          throw new Error(`AbortError: ${error.message}`)
        } else if (error.name === 'NotAllowedError') {
          throw new Error(`NotAllowedError: ${error.message}`)
        } else if (error.name === 'NotFoundError') {
          throw new Error(`NotFoundError: ${error.message}`)
        } else if (error.name === 'InvalidStateError') {
          throw new Error(`Invalid state: ${error.message}`)
        }
      }

      throw new Error(`Failed to get media stream: ${error}`)
    }
  }


  // æ£€æŸ¥æ‰©å±•ç¯å¢ƒå’Œæƒé™
  async function checkExtensionEnvironment() {
    try {
      // æ£€æŸ¥Chromeæ‰©å±•ç¯å¢ƒ
      if (typeof chrome === 'undefined' || !chrome.runtime) {
        throw new Error('Chromeæ‰©å±•ç¯å¢ƒä¸å¯ç”¨')
      }

      // æ£€æŸ¥å¿…è¦çš„API
      if (!chrome.runtime.sendMessage) {
        throw new Error('Chromeæ¶ˆæ¯APIä¸å¯ç”¨')
      }

      // æ£€æŸ¥MediaRecorderæ”¯æŒ
      if (typeof MediaRecorder === 'undefined') {
        throw new Error('æµè§ˆå™¨ä¸æ”¯æŒMediaRecorder')
      }

      // æ£€æŸ¥getUserMediaæ”¯æŒ
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error('æµè§ˆå™¨ä¸æ”¯æŒgetUserMedia')
      }

      console.log('âœ… Extension environment check passed')

    } catch (error) {
      console.error('âŒ Extension environment check failed:', error)
      handleRecordingError(error instanceof Error ? error.message : 'æ‰©å±•ç¯å¢ƒæ£€æŸ¥å¤±è´¥')
    }
  }

  // ç»„ä»¶æŒ‚è½½æ—¶çš„åˆå§‹åŒ–
  onMount(() => {
    console.log('ğŸ“± Sidepanel mounted with Worker system')

    // æ£€æŸ¥æ‰©å±•ç¯å¢ƒ

/* LEGACY PORT BLOCK REMOVED START */
	    // æ³¨å†Œæˆä¸ºå…ƒç´ /åŒºåŸŸç¼–ç æµçš„æ¶ˆè´¹è€…ï¼ˆé€šè¿‡ background è½¬å‘ï¼‰
	    if (typeof chrome !== 'undefined' && chrome.runtime && chrome.tabs) {
	      try {
	        /* legacy element-stream-consumer removed */

	        // ç»‘å®šå½“å‰æ´»åŠ¨æ ‡ç­¾é¡µ id
	        chrome.tabs.query({ active: true, currentWindow: true }, (tabs) => {
	          const tabId = tabs?.[0]?.id
	          if (typeof tabId === 'number') {

	          }
	        })
	        // ç›‘å¬è½¬å‘è¿‡æ¥çš„ start/meta/chunk/end
	        elementStreamPort.onMessage.addListener(async (msg: any) => {
	          switch (msg?.type) {
	            case 'start':
	              streamingChunks = []
                elementUIStatus = 'recording'
	              console.log('[Stream][Sidepanel] start received; reset chunks')
	              break
	            case 'meta':
	              streamingMeta = msg.metadata
	              console.log('[Stream][Sidepanel] meta received', { width: streamingMeta?.width, height: streamingMeta?.height, codec: streamingMeta?.codec, startTime: streamingMeta?.startTime })
	              break
	            case 'chunk': {
	              // try {
	              //   const buf: ArrayBuffer | undefined = msg.data
	              //   const view = buf
	              //   streamingChunks.push({
	              //     data: view,
	              //     timestamp: Number(msg.ts) || 0,
	              //     type: msg.kind === 'key' ? 'key' : 'delta',
	              //     size: (typeof msg.size === 'number' && msg.size > 0) ? msg.size : view.byteLength,
	              //     codedWidth: streamingMeta?.width || 1920,
	              //     codedHeight: streamingMeta?.height || 1080,
	              //     codec: streamingMeta?.codec || 'vp8'
	              //   })

	              // } catch (e) {
	              //   console.warn('[Sidepanel] failed to accumulate chunk', e)
	              // }
	              //   const n = streamingChunks.length
	              //   if (n <= 3 || n % 100 === 0) {
	              //     console.log('[Stream][Sidepanel] chunk received', { count: n, kind: msg.kind, size: msg.size })
	              //   }

	              break
	            }
	            case 'end':
	              console.log('[Stream][Sidepanel] end received', { chunks: streamingChunks.length, hasMeta: !!streamingMeta })

                elementUIStatus = 'completed';
                openInStudio();

	              // // ä½¿ç”¨ä¸â€œå¤§åŒ…â€ä¸€è‡´çš„æ•°æ®ç»“æ„è¿›è¡Œå¤„ç†
	              // if (streamingChunks.length > 0) {

		            //   // finalize OPFS for element/region stream
		            //   // try { await finalizeOpfsWriter() } catch (e) { console.warn('[OPFS] finalize (element-stream) failed', e) }

	              //   handleElementRecordingData({ encodedChunks: streamingChunks, metadata: streamingMeta })
                //   elementUIStatus = 'completed'

	              // }
	              // streamingChunks = []


	              // streamingMeta = null
	              // break
	            default:
	              break
	          }
	        })
	      } catch (e) {
	        console.warn('element-stream-consumer connect failed', e)
	      }
/* LEGACY PORT BLOCK REMOVED END */
	    }

    checkExtensionEnvironment()

    // æ£€æŸ¥ Worker ç¯å¢ƒ
    checkWorkerEnvironment()

    // è®¾ç½®å…ƒç´ å½•åˆ¶é›†æˆç›‘å¬å™¨
    const elementRecordingListener = (data: ElementRecordingData) => {
      console.log('ğŸ¬ [Sidepanel] Element recording integration callback:', data)

      // è½¬æ¢å¹¶è®¾ç½®æ•°æ®
      const compatibleChunks = elementRecordingIntegration.convertToMainSystemFormat(data)
      workerEncodedChunks = compatibleChunks

      // æ›´æ–°çŠ¶æ€
      recordingStore.updateStatus('completed')
      recordingStore.setEngine('webcodecs')

      // è·å–æ‘˜è¦
      const summary = elementRecordingIntegration.getRecordingSummary(data)
      console.log('ğŸ“Š [Sidepanel] Recording summary:', summary)
    }

    elementRecordingIntegration.onDataReceived(elementRecordingListener)

    // ç›‘å¬æ¥è‡ªbackground/contentscriptçš„æ¶ˆæ¯
    const messageListener = (message: any) => {
      if (message.action === 'downloadComplete') {
        console.log('âœ… Download completed:', message.downloadId)
      } else if (message.type === 'ELEMENT_RECORDING_DATA') {
        // å¤„ç†å…ƒç´ å½•åˆ¶æ•°æ®
        handleElementRecordingData(message)
      } else if (message.type === 'ELEMENT_RECORDING_READY') {
        // å¤„ç†å…ƒç´ å½•åˆ¶å°±ç»ªé€šçŸ¥
        handleElementRecordingReady(message.data)
      } else if (message.type === 'CAPTURE_FAILED') {
        console.warn('âŒ [Sidepanel] Capture failed:', message.error)
        // å¦‚æœ UI æ­£å¤„äºè¯·æ±‚ä¸­ï¼Œå›é€€åˆ° idle
        if (elementUIStatus === 'requesting') elementUIStatus = 'idle'
      } else if (message.type === 'STATE_UPDATE') {
        // ä»…åœ¨â€œè¯·æ±‚ä¸­â€æ—¶ä½¿ç”¨å®ƒæ¥è§£é™¤å¡æ­»
        if (elementUIStatus === 'requesting') {
          const rec = !!message.state?.recording
          // å¦‚æœåå°æœªè¿›å…¥ recordingï¼Œåˆ™å›é€€åˆ° idle
          if (!rec) elementUIStatus = 'idle'
        }
      } else if (message.type === 'STREAM_START') {
        elementUIStatus = 'recording'
      } else if (message.type === 'STREAM_END') {
        // ç”± background åœ¨ OPFS_RECORDING_READY æ—¶æ‰“å¼€ Studioï¼›è¿™é‡Œä»…å¤ä½æŒ‰é’®
        elementUIStatus = 'idle'
      }
    }

    if (typeof chrome !== 'undefined' && chrome.runtime) {

      chrome.runtime.onMessage.addListener(messageListener)
    }

    return () => {
      if (typeof chrome !== 'undefined' && chrome.runtime) {
        chrome.runtime.onMessage.removeListener(messageListener)
      }
      // æ¸…ç†å…ƒç´ å½•åˆ¶ç›‘å¬å™¨
      elementRecordingIntegration.removeListener(elementRecordingListener)
    }
  })

  // ç»„ä»¶é”€æ¯æ—¶æ¸…ç†
  onDestroy(() => {
    console.log('ğŸ“± Sidepanel unmounted, cleaning up...')
    cleanup()
  })
</script>

<svelte:head>
  <title>å±å¹•å½•åˆ¶</title>
</svelte:head>

<!-- å½•åˆ¶é¢æ¿ï¼ˆæ—  mini æ¨¡å¼ï¼‰ -->
  <div class="flex flex-col items-center justify-center min-h-screen p-4 bg-gradient-to-br from-gray-50 to-gray-100 transition-all duration-300 ease-in-out">
{#if showHandoffNotice}
  <div class="fixed top-3 left-1/2 -translate-x-1/2 z-50 px-3 py-1.5 rounded-md bg-indigo-600 text-white text-xs shadow-lg">
    {handoffText}
  </div>
{/if}

    <!-- ç®€åŒ–çš„é¡µé¢æ ‡é¢˜ -->
    <div class="text-center mb-8 animate-fade-in">
      <h1 class="text-2xl font-bold text-gray-800 mb-1 transition-colors duration-200">å±å¹•å½•åˆ¶å·¥å…·</h1>
      <p class="text-sm text-gray-600 transition-colors duration-200">é«˜æ€§èƒ½ WebCodecs å½•åˆ¶å¼•æ“</p>
    </div>

    <!-- å…ƒç´ /åŒºåŸŸé€‰æ‹©é¢æ¿ -->
    <div class="max-w-md w-full mb-6">
      <ElementRegionSelector />
    </div>

    <!-- å½•åˆ¶æ§åˆ¶æŒ‰é’® -->
    {#if shouldShowElementRecordButton}
      <!-- Element/Region å½•åˆ¶æŒ‰é’® -->
      <div class="max-w-md w-full mb-6">
        <RecordButton
          isRecording={recording}
          status={elementUIStatus}
          onclick={handleToggleCapture}
        />
      </div>
    {:else if shouldShowWebCodecsRecordButton}
      <!-- Tab/Window/Screen å½•åˆ¶æŒ‰é’® -->
      <div class="max-w-md w-full mb-6">
        <RecordButton
          isRecording={workerIsRecording}
          status={workerStatus}
          onclick={handleWorkerRecordButtonClick}
        />
      </div>
    {/if}

      <!-- é”™è¯¯ä¿¡æ¯æ˜¾ç¤º -->
      {#if workerErrorMessage || workerEnvironmentIssues.length > 0}
        <div class="bg-red-50 border border-red-200 rounded-lg p-4 mb-4">
          {#if workerErrorMessage}
            <div class="flex items-start gap-2 mb-2">
              <TriangleAlert class="w-4 h-4 text-red-500 mt-0.5 flex-shrink-0" />
              <div>
                <div class="text-sm font-medium text-red-800">å½•åˆ¶é”™è¯¯</div>
                <div class="text-xs text-red-600 mt-1">{workerErrorMessage}</div>
              </div>
            </div>
          {/if}

          {#if workerEnvironmentIssues.length > 0}
            <div class="flex items-start gap-2">
              <TriangleAlert class="w-4 h-4 text-red-500 mt-0.5 flex-shrink-0" />
              <div>
                <div class="text-sm font-medium text-red-800">ç¯å¢ƒé—®é¢˜</div>
                <ul class="text-xs text-red-600 mt-1 space-y-1">
                  {#each workerEnvironmentIssues as issue}
                    <li class="flex items-center gap-1">
                      <div class="w-1 h-1 bg-red-400 rounded-full"></div>
                      {issue}
                    </li>
                  {/each}
                </ul>
              </div>
            </div>
          {/if}
        </div>
      {/if}
  </div>

<style>
  /* è‡ªå®šä¹‰åŠ¨ç”»ç±» */
  @keyframes fade-in {
    from {
      opacity: 0;
      transform: translateY(10px);
    }
    to {
      opacity: 1;
      transform: translateY(0);
    }
  }

  .animate-fade-in {
    animation: fade-in 0.5s ease-out;
  }

  /* ä¼˜åŒ–æ»šåŠ¨æ¡æ ·å¼ */
  :global(.overflow-y-auto::-webkit-scrollbar) {
    width: 6px;
  }

  :global(.overflow-y-auto::-webkit-scrollbar-track) {
    background: transparent;
  }

  :global(.overflow-y-auto::-webkit-scrollbar-thumb) {
    background: rgba(156, 163, 175, 0.5);
    border-radius: 3px;
  }

  :global(.overflow-y-auto::-webkit-scrollbar-thumb:hover) {
    background: rgba(156, 163, 175, 0.8);
  }
</style>

